# @stratix/queue éƒ¨ç½²å’Œè¿ç»´æŒ‡å—

## ğŸ¯ éƒ¨ç½²æ¶æ„

### ç”Ÿäº§ç¯å¢ƒæ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        è´Ÿè½½å‡è¡¡å±‚                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Nginx/HAProxy  â”‚  Nginx/HAProxy  â”‚  Nginx/HAProxy             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        åº”ç”¨æœåŠ¡å±‚                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  App Instance 1 â”‚  App Instance 2 â”‚  App Instance 3            â”‚
â”‚  (Producer +    â”‚  (Producer +    â”‚  (Consumer)                â”‚
â”‚   Consumer)     â”‚   Consumer)     â”‚                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Redis Cluster å±‚                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Redis Master 1 â”‚  Redis Master 2 â”‚  Redis Master 3            â”‚
â”‚  (Slot 0-5460)  â”‚  (Slot 5461-    â”‚  (Slot 10923-              â”‚
â”‚                 â”‚   10922)        â”‚   16383)                   â”‚
â”‚  Redis Slave 1  â”‚  Redis Slave 2  â”‚  Redis Slave 3             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ç›‘æ§å’Œæ—¥å¿—å±‚                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Prometheus     â”‚  Grafana        â”‚  ELK Stack                 â”‚
â”‚  AlertManager   â”‚  Redis Insight  â”‚  Jaeger                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ³ Dockeréƒ¨ç½²

### 1. åº”ç”¨å®¹å™¨åŒ–

```dockerfile
# Dockerfile
FROM node:20-alpine AS builder

WORKDIR /app
COPY package*.json ./
RUN npm ci --only=production

FROM node:20-alpine AS runtime

# å®‰è£…è¿è¡Œæ—¶ä¾èµ–
RUN apk add --no-cache \
    dumb-init \
    curl \
    && addgroup -g 1001 -S nodejs \
    && adduser -S nodejs -u 1001

WORKDIR /app

# å¤åˆ¶ä¾èµ–å’Œåº”ç”¨ä»£ç 
COPY --from=builder /app/node_modules ./node_modules
COPY --chown=nodejs:nodejs . .

# è®¾ç½®ç¯å¢ƒå˜é‡
ENV NODE_ENV=production
ENV NODE_OPTIONS="--max-old-space-size=4096 --enable-source-maps"

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD curl -f http://localhost:3000/health || exit 1

# ä½¿ç”¨érootç”¨æˆ·
USER nodejs

# ä¼˜é›…å…³é—­å¤„ç†
ENTRYPOINT ["dumb-init", "--"]
CMD ["node", "dist/index.js"]
```

### 2. Docker Composeéƒ¨ç½²

```yaml
# docker-compose.yml
version: '3.8'

services:
  # åº”ç”¨æœåŠ¡
  queue-app-1:
    build: .
    container_name: queue-app-1
    ports:
      - "3001:3000"
    environment:
      - NODE_ENV=production
      - REDIS_CLUSTER_NODES=redis-master-1:7001,redis-master-2:7002,redis-master-3:7003
      - APP_ROLE=producer,consumer
    volumes:
      - ./logs:/app/logs
    networks:
      - queue-network
    depends_on:
      - redis-master-1
      - redis-master-2
      - redis-master-3
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2'
        reservations:
          memory: 2G
          cpus: '1'

  queue-app-2:
    build: .
    container_name: queue-app-2
    ports:
      - "3002:3000"
    environment:
      - NODE_ENV=production
      - REDIS_CLUSTER_NODES=redis-master-1:7001,redis-master-2:7002,redis-master-3:7003
      - APP_ROLE=consumer
    volumes:
      - ./logs:/app/logs
    networks:
      - queue-network
    depends_on:
      - redis-master-1
      - redis-master-2
      - redis-master-3
    restart: unless-stopped

  # Redisé›†ç¾¤ (å‚è€ƒredis-cluster-config.md)
  redis-master-1:
    image: redis:7.2-alpine
    container_name: redis-master-1
    ports:
      - "7001:7001"
      - "17001:17001"
    volumes:
      - ./redis-config/master-1.conf:/usr/local/etc/redis/redis.conf
      - redis-master-1-data:/data
    command: redis-server /usr/local/etc/redis/redis.conf
    networks:
      - queue-network
    restart: unless-stopped

  # ç›‘æ§æœåŠ¡
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    networks:
      - queue-network
    restart: unless-stopped

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin123
    volumes:
      - grafana-data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
    networks:
      - queue-network
    restart: unless-stopped

  # è´Ÿè½½å‡è¡¡
  nginx:
    image: nginx:alpine
    container_name: nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./nginx/ssl:/etc/nginx/ssl
    networks:
      - queue-network
    depends_on:
      - queue-app-1
      - queue-app-2
    restart: unless-stopped

volumes:
  redis-master-1-data:
  redis-master-2-data:
  redis-master-3-data:
  prometheus-data:
  grafana-data:

networks:
  queue-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16
```

## â˜¸ï¸ Kuberneteséƒ¨ç½²

### 1. å‘½åç©ºé—´å’Œé…ç½®

```yaml
# namespace.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: queue-system
  labels:
    name: queue-system

---
# configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: queue-config
  namespace: queue-system
data:
  redis-nodes: "redis-0.redis:6379,redis-1.redis:6379,redis-2.redis:6379"
  log-level: "info"
  batch-size: "100"
  pool-size: "50"

---
# secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: queue-secrets
  namespace: queue-system
type: Opaque
data:
  redis-password: <base64-encoded-password>
  app-secret: <base64-encoded-secret>
```

### 2. Redisé›†ç¾¤éƒ¨ç½²

```yaml
# redis-cluster.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: redis
  namespace: queue-system
spec:
  serviceName: redis
  replicas: 6
  selector:
    matchLabels:
      app: redis
  template:
    metadata:
      labels:
        app: redis
    spec:
      containers:
      - name: redis
        image: redis:7.2-alpine
        ports:
        - containerPort: 6379
          name: client
        - containerPort: 16379
          name: gossip
        command:
        - redis-server
        args:
        - /etc/redis/redis.conf
        - --cluster-enabled
        - "yes"
        - --cluster-config-file
        - nodes.conf
        - --cluster-node-timeout
        - "5000"
        - --appendonly
        - "yes"
        - --protected-mode
        - "no"
        volumeMounts:
        - name: data
          mountPath: /data
        - name: config
          mountPath: /etc/redis
        resources:
          requests:
            memory: "4Gi"
            cpu: "2"
          limits:
            memory: "8Gi"
            cpu: "4"
        livenessProbe:
          exec:
            command:
            - redis-cli
            - ping
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          exec:
            command:
            - redis-cli
            - ping
          initialDelaySeconds: 5
          periodSeconds: 5
      volumes:
      - name: config
        configMap:
          name: redis-config
  volumeClaimTemplates:
  - metadata:
      name: data
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 100Gi
      storageClassName: fast-ssd

---
apiVersion: v1
kind: Service
metadata:
  name: redis
  namespace: queue-system
spec:
  clusterIP: None
  selector:
    app: redis
  ports:
  - port: 6379
    targetPort: 6379
    name: client
  - port: 16379
    targetPort: 16379
    name: gossip
```

### 3. åº”ç”¨éƒ¨ç½²

```yaml
# app-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: queue-app
  namespace: queue-system
spec:
  replicas: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  selector:
    matchLabels:
      app: queue-app
  template:
    metadata:
      labels:
        app: queue-app
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "3000"
        prometheus.io/path: "/metrics"
    spec:
      containers:
      - name: queue-app
        image: queue-app:latest
        ports:
        - containerPort: 3000
          name: http
        env:
        - name: NODE_ENV
          value: "production"
        - name: REDIS_CLUSTER_NODES
          valueFrom:
            configMapKeyRef:
              name: queue-config
              key: redis-nodes
        - name: REDIS_PASSWORD
          valueFrom:
            secretKeyRef:
              name: queue-secrets
              key: redis-password
        - name: LOG_LEVEL
          valueFrom:
            configMapKeyRef:
              name: queue-config
              key: log-level
        resources:
          requests:
            memory: "2Gi"
            cpu: "1"
          limits:
            memory: "4Gi"
            cpu: "2"
        livenessProbe:
          httpGet:
            path: /health
            port: 3000
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /ready
            port: 3000
          initialDelaySeconds: 5
          periodSeconds: 5
          timeoutSeconds: 3
          failureThreshold: 3
        lifecycle:
          preStop:
            exec:
              command: ["/bin/sh", "-c", "sleep 15"]
        volumeMounts:
        - name: logs
          mountPath: /app/logs
      volumes:
      - name: logs
        emptyDir: {}
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - queue-app
              topologyKey: kubernetes.io/hostname

---
apiVersion: v1
kind: Service
metadata:
  name: queue-app-service
  namespace: queue-system
spec:
  selector:
    app: queue-app
  ports:
  - port: 80
    targetPort: 3000
    name: http
  type: ClusterIP

---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: queue-app-ingress
  namespace: queue-system
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
spec:
  tls:
  - hosts:
    - queue.example.com
    secretName: queue-tls
  rules:
  - host: queue.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: queue-app-service
            port:
              number: 80
```

### 4. æ°´å¹³æ‰©ç¼©å®¹

```yaml
# hpa.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: queue-app-hpa
  namespace: queue-system
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: queue-app
  minReplicas: 3
  maxReplicas: 20
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  - type: Pods
    pods:
      metric:
        name: queue_messages_per_second
      target:
        type: AverageValue
        averageValue: "1000"
  behavior:
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 100
        periodSeconds: 15
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 10
        periodSeconds: 60
```

## ğŸ“Š ç›‘æ§éƒ¨ç½²

### 1. Prometheusé…ç½®

```yaml
# prometheus-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: queue-system
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      evaluation_interval: 15s
    
    rule_files:
      - "/etc/prometheus/rules/*.yml"
    
    alerting:
      alertmanagers:
      - static_configs:
        - targets:
          - alertmanager:9093
    
    scrape_configs:
    - job_name: 'queue-app'
      kubernetes_sd_configs:
      - role: pod
        namespaces:
          names:
          - queue-system
      relabel_configs:
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
        action: replace
        target_label: __metrics_path__
        regex: (.+)
      - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
        action: replace
        regex: ([^:]+)(?::\d+)?;(\d+)
        replacement: $1:$2
        target_label: __address__
    
    - job_name: 'redis-cluster'
      static_configs:
      - targets:
        - redis-0.redis:6379
        - redis-1.redis:6379
        - redis-2.redis:6379
        - redis-3.redis:6379
        - redis-4.redis:6379
        - redis-5.redis:6379
      metrics_path: /metrics
      scrape_interval: 10s

  alert-rules.yml: |
    groups:
    - name: queue-alerts
      rules:
      - alert: HighMessageLatency
        expr: queue_message_latency_p99 > 100
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High message latency detected"
          description: "P99 latency is {{ $value }}ms"
      
      - alert: QueueBacklog
        expr: queue_length > 10000
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "Queue backlog detected"
          description: "Queue {{ $labels.queue }} has {{ $value }} messages"
      
      - alert: RedisNodeDown
        expr: up{job="redis-cluster"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Redis node is down"
          description: "Redis node {{ $labels.instance }} is down"
```

### 2. Grafanaä»ªè¡¨æ¿

```json
{
  "dashboard": {
    "title": "Queue System Dashboard",
    "panels": [
      {
        "title": "Message Throughput",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(queue_messages_sent_total[5m])",
            "legendFormat": "Messages Sent/sec"
          },
          {
            "expr": "rate(queue_messages_processed_total[5m])",
            "legendFormat": "Messages Processed/sec"
          }
        ]
      },
      {
        "title": "Message Latency",
        "type": "graph",
        "targets": [
          {
            "expr": "queue_message_latency_p50",
            "legendFormat": "P50"
          },
          {
            "expr": "queue_message_latency_p95",
            "legendFormat": "P95"
          },
          {
            "expr": "queue_message_latency_p99",
            "legendFormat": "P99"
          }
        ]
      },
      {
        "title": "Queue Length",
        "type": "graph",
        "targets": [
          {
            "expr": "queue_length",
            "legendFormat": "{{ queue }}"
          }
        ]
      },
      {
        "title": "Redis Cluster Status",
        "type": "table",
        "targets": [
          {
            "expr": "redis_cluster_nodes",
            "format": "table"
          }
        ]
      }
    ]
  }
}
```

## ğŸ”§ è¿ç»´æ“ä½œ

### 1. éƒ¨ç½²è„šæœ¬

```bash
#!/bin/bash
# deploy.sh

set -e

NAMESPACE="queue-system"
IMAGE_TAG=${1:-latest}

echo "å¼€å§‹éƒ¨ç½²é˜Ÿåˆ—ç³»ç»Ÿ..."

# åˆ›å»ºå‘½åç©ºé—´
kubectl create namespace $NAMESPACE --dry-run=client -o yaml | kubectl apply -f -

# éƒ¨ç½²é…ç½®
kubectl apply -f k8s/configmap.yaml
kubectl apply -f k8s/secret.yaml

# éƒ¨ç½²Redisé›†ç¾¤
echo "éƒ¨ç½²Redisé›†ç¾¤..."
kubectl apply -f k8s/redis-cluster.yaml

# ç­‰å¾…Redisé›†ç¾¤å°±ç»ª
echo "ç­‰å¾…Redisé›†ç¾¤å¯åŠ¨..."
kubectl wait --for=condition=ready pod -l app=redis -n $NAMESPACE --timeout=300s

# åˆå§‹åŒ–Redisé›†ç¾¤
echo "åˆå§‹åŒ–Redisé›†ç¾¤..."
kubectl exec -n $NAMESPACE redis-0 -- redis-cli --cluster create \
  redis-0.redis:6379 redis-1.redis:6379 redis-2.redis:6379 \
  redis-3.redis:6379 redis-4.redis:6379 redis-5.redis:6379 \
  --cluster-replicas 1 --cluster-yes

# éƒ¨ç½²åº”ç”¨
echo "éƒ¨ç½²åº”ç”¨..."
sed "s/IMAGE_TAG/$IMAGE_TAG/g" k8s/app-deployment.yaml | kubectl apply -f -

# éƒ¨ç½²ç›‘æ§
echo "éƒ¨ç½²ç›‘æ§..."
kubectl apply -f k8s/monitoring/

# ç­‰å¾…åº”ç”¨å°±ç»ª
echo "ç­‰å¾…åº”ç”¨å¯åŠ¨..."
kubectl wait --for=condition=available deployment/queue-app -n $NAMESPACE --timeout=300s

# æ£€æŸ¥éƒ¨ç½²çŠ¶æ€
echo "æ£€æŸ¥éƒ¨ç½²çŠ¶æ€..."
kubectl get pods -n $NAMESPACE
kubectl get services -n $NAMESPACE

echo "éƒ¨ç½²å®Œæˆï¼"
```

### 2. å¥åº·æ£€æŸ¥è„šæœ¬

```bash
#!/bin/bash
# health-check.sh

NAMESPACE="queue-system"

echo "=== é˜Ÿåˆ—ç³»ç»Ÿå¥åº·æ£€æŸ¥ ==="

# æ£€æŸ¥PodçŠ¶æ€
echo "1. æ£€æŸ¥PodçŠ¶æ€..."
kubectl get pods -n $NAMESPACE

# æ£€æŸ¥Redisé›†ç¾¤çŠ¶æ€
echo -e "\n2. æ£€æŸ¥Redisé›†ç¾¤çŠ¶æ€..."
kubectl exec -n $NAMESPACE redis-0 -- redis-cli cluster info | grep cluster_state
kubectl exec -n $NAMESPACE redis-0 -- redis-cli cluster nodes

# æ£€æŸ¥åº”ç”¨å¥åº·çŠ¶æ€
echo -e "\n3. æ£€æŸ¥åº”ç”¨å¥åº·çŠ¶æ€..."
for pod in $(kubectl get pods -n $NAMESPACE -l app=queue-app -o jsonpath='{.items[*].metadata.name}'); do
  echo "æ£€æŸ¥ $pod..."
  kubectl exec -n $NAMESPACE $pod -- curl -f http://localhost:3000/health || echo "å¥åº·æ£€æŸ¥å¤±è´¥"
done

# æ£€æŸ¥æœåŠ¡çŠ¶æ€
echo -e "\n4. æ£€æŸ¥æœåŠ¡çŠ¶æ€..."
kubectl get services -n $NAMESPACE

# æ£€æŸ¥èµ„æºä½¿ç”¨æƒ…å†µ
echo -e "\n5. æ£€æŸ¥èµ„æºä½¿ç”¨æƒ…å†µ..."
kubectl top pods -n $NAMESPACE

echo -e "\nå¥åº·æ£€æŸ¥å®Œæˆï¼"
```

### 3. æ‰©å®¹è„šæœ¬

```bash
#!/bin/bash
# scale.sh

NAMESPACE="queue-system"
REPLICAS=${1:-5}

echo "æ‰©å®¹åº”ç”¨åˆ° $REPLICAS ä¸ªå‰¯æœ¬..."

kubectl scale deployment queue-app --replicas=$REPLICAS -n $NAMESPACE

echo "ç­‰å¾…æ‰©å®¹å®Œæˆ..."
kubectl wait --for=condition=available deployment/queue-app -n $NAMESPACE --timeout=300s

echo "å½“å‰PodçŠ¶æ€:"
kubectl get pods -n $NAMESPACE -l app=queue-app

echo "æ‰©å®¹å®Œæˆï¼"
```

### 4. å¤‡ä»½è„šæœ¬

```bash
#!/bin/bash
# backup.sh

NAMESPACE="queue-system"
BACKUP_DIR="/backup/$(date +%Y%m%d_%H%M%S)"

mkdir -p $BACKUP_DIR

echo "å¼€å§‹å¤‡ä»½Redisæ•°æ®..."

# å¤‡ä»½æ¯ä¸ªRedisèŠ‚ç‚¹
for i in {0..5}; do
  echo "å¤‡ä»½ redis-$i..."
  kubectl exec -n $NAMESPACE redis-$i -- redis-cli BGSAVE
  
  # ç­‰å¾…å¤‡ä»½å®Œæˆ
  while [ "$(kubectl exec -n $NAMESPACE redis-$i -- redis-cli LASTSAVE)" = "$(kubectl exec -n $NAMESPACE redis-$i -- redis-cli LASTSAVE)" ]; do
    sleep 1
  done
  
  # å¤åˆ¶å¤‡ä»½æ–‡ä»¶
  kubectl cp $NAMESPACE/redis-$i:/data/dump.rdb $BACKUP_DIR/redis-$i-dump.rdb
done

# å¤‡ä»½é…ç½®
kubectl get configmap -n $NAMESPACE -o yaml > $BACKUP_DIR/configmaps.yaml
kubectl get secret -n $NAMESPACE -o yaml > $BACKUP_DIR/secrets.yaml

echo "å¤‡ä»½å®Œæˆï¼Œä¿å­˜åœ¨: $BACKUP_DIR"
```

## ğŸ“‹ è¿ç»´æ£€æŸ¥æ¸…å•

### æ—¥å¸¸æ£€æŸ¥
- [ ] é›†ç¾¤èŠ‚ç‚¹çŠ¶æ€
- [ ] åº”ç”¨Podå¥åº·çŠ¶æ€
- [ ] é˜Ÿåˆ—é•¿åº¦ç›‘æ§
- [ ] æ¶ˆæ¯å¤„ç†å»¶è¿Ÿ
- [ ] é”™è¯¯ç‡ç»Ÿè®¡
- [ ] èµ„æºä½¿ç”¨æƒ…å†µ

### å®šæœŸç»´æŠ¤
- [ ] æ•°æ®å¤‡ä»½
- [ ] æ—¥å¿—æ¸…ç†
- [ ] æ€§èƒ½è°ƒä¼˜
- [ ] å®‰å…¨æ›´æ–°
- [ ] å®¹é‡è§„åˆ’
- [ ] æ•…éšœæ¼”ç»ƒ

### å‘Šè­¦å¤„ç†
- [ ] é«˜å»¶è¿Ÿå‘Šè­¦
- [ ] é˜Ÿåˆ—ç§¯å‹å‘Šè­¦
- [ ] èŠ‚ç‚¹æ•…éšœå‘Šè­¦
- [ ] èµ„æºä¸è¶³å‘Šè­¦
- [ ] é”™è¯¯ç‡å‘Šè­¦
- [ ] è¿æ¥æ•°å‘Šè­¦
