# @stratix/tasks ä½¿ç”¨æŒ‡å—

## ğŸ“‹ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…

```bash
# ä½¿ç”¨ npm
npm install @stratix/tasks

# ä½¿ç”¨ pnpm
pnpm add @stratix/tasks

# ä½¿ç”¨ yarn
yarn add @stratix/tasks
```

### 2. åŸºç¡€é…ç½®

```typescript
// stratix.config.ts
import { createStratixConfig } from '@stratix/core';
import tasksPlugin from '@stratix/tasks';
import databasePlugin from '@stratix/database';

export default createStratixConfig({
  plugins: [
    // æ•°æ®åº“æ’ä»¶ï¼ˆå¿…éœ€ï¼‰
    [databasePlugin, {
      connections: {
        default: {
          type: 'mysql',
          host: 'localhost',
          port: 3306,
          database: 'workflows',
          username: 'root',
          password: 'password'
        }
      }
    }],
    
    // å·¥ä½œæµæ’ä»¶
    [tasksPlugin, {
      // æ’ä»¶é…ç½®é€‰é¡¹
      autoStart: true,
      maxConcurrentWorkflows: 100,
      taskTimeout: 300000, // 5åˆ†é’Ÿ
      retryPolicy: {
        maxAttempts: 3,
        backoffStrategy: 'exponential'
      }
    }]
  ]
});
```

### 3. å¯åŠ¨åº”ç”¨

```typescript
// app.ts
import { createStratixApp } from '@stratix/core';
import config from './stratix.config.js';

const app = createStratixApp(config);

await app.start();
console.log('ğŸš€ Stratix åº”ç”¨å¯åŠ¨æˆåŠŸ');
```

## ğŸ”§ å·¥ä½œæµå®šä¹‰

### 1. åˆ›å»ºå·¥ä½œæµå®šä¹‰

åœ¨ `workflows/definitions/` ç›®å½•ä¸‹åˆ›å»ºå·¥ä½œæµå®šä¹‰æ–‡ä»¶ï¼š

```typescript
// workflows/definitions/data-processing.ts
import { WorkflowDefinition, TaskType } from '@stratix/tasks';

export const dataProcessingWorkflow: WorkflowDefinition = {
  id: 'data-processing-v1',
  name: 'Data Processing Pipeline',
  version: '1.0.0',
  description: 'æ•°æ®å¤„ç†ç®¡é“å·¥ä½œæµ',
  
  // å·¥ä½œæµå˜é‡
  variables: {
    batchSize: 1000,
    timeout: 300000
  },
  
  // ä»»åŠ¡å®šä¹‰
  tasks: [
    {
      id: 'validate',
      name: 'æ•°æ®éªŒè¯',
      type: TaskType.EXECUTOR,
      executor: 'data-validator',
      parameters: {
        schema: 'user-data-schema',
        strictMode: true
      },
      timeout: 60000,
      retryPolicy: {
        maxAttempts: 2,
        backoffStrategy: 'fixed',
        delay: 5000
      }
    },
    {
      id: 'transform',
      name: 'æ•°æ®è½¬æ¢',
      type: TaskType.EXECUTOR,
      executor: 'data-transformer',
      dependencies: ['validate'],
      parameters: {
        outputFormat: 'json',
        compression: true
      }
    },
    {
      id: 'parallel-processing',
      name: 'å¹¶è¡Œå¤„ç†',
      type: TaskType.PARALLEL,
      dependencies: ['transform'],
      tasks: [
        {
          id: 'save-database',
          name: 'ä¿å­˜åˆ°æ•°æ®åº“',
          type: TaskType.EXECUTOR,
          executor: 'database-saver'
        },
        {
          id: 'save-file',
          name: 'ä¿å­˜åˆ°æ–‡ä»¶',
          type: TaskType.EXECUTOR,
          executor: 'file-saver'
        }
      ]
    },
    {
      id: 'notify',
      name: 'å‘é€é€šçŸ¥',
      type: TaskType.EXECUTOR,
      executor: 'notification-sender',
      dependencies: ['parallel-processing'],
      condition: '${workflow.status} === "completed"'
    }
  ],
  
  // è§¦å‘å™¨é…ç½®
  triggers: [
    {
      type: 'cron',
      config: {
        cron: '0 2 * * *', // æ¯å¤©å‡Œæ™¨2ç‚¹
        timezone: 'Asia/Shanghai'
      }
    },
    {
      type: 'event',
      config: {
        eventType: 'file.uploaded',
        filter: {
          fileType: 'csv',
          size: { $lt: 100000000 } // å°äº100MB
        }
      }
    }
  ],
  
  // é”™è¯¯å¤„ç†
  onError: {
    strategy: 'retry',
    maxAttempts: 3,
    notifyOnFailure: true
  }
};

// å¯¼å‡ºå·¥ä½œæµå®šä¹‰ï¼ˆè‡ªåŠ¨å‘ç°æœºåˆ¶ä¼šæ‰«ææ­¤å¯¼å‡ºï¼‰
export default dataProcessingWorkflow;
```

### 2. æ¡ä»¶å’Œåˆ†æ”¯

```typescript
// workflows/definitions/conditional-workflow.ts
export const conditionalWorkflow: WorkflowDefinition = {
  id: 'conditional-processing',
  name: 'Conditional Processing',
  version: '1.0.0',
  
  tasks: [
    {
      id: 'check-file-size',
      name: 'æ£€æŸ¥æ–‡ä»¶å¤§å°',
      type: TaskType.CONDITION,
      condition: '${input.fileSize} > 1000000', // å¤§äº1MB
      onTrue: ['large-file-processing'],
      onFalse: ['small-file-processing']
    },
    {
      id: 'large-file-processing',
      name: 'å¤§æ–‡ä»¶å¤„ç†',
      type: TaskType.EXECUTOR,
      executor: 'large-file-processor'
    },
    {
      id: 'small-file-processing',
      name: 'å°æ–‡ä»¶å¤„ç†',
      type: TaskType.EXECUTOR,
      executor: 'small-file-processor'
    },
    {
      id: 'finalize',
      name: 'å®Œæˆå¤„ç†',
      type: TaskType.EXECUTOR,
      executor: 'finalizer',
      dependencies: ['large-file-processing', 'small-file-processing'],
      dependencyType: 'any' // ä»»æ„ä¸€ä¸ªä¾èµ–å®Œæˆå³å¯æ‰§è¡Œ
    }
  ]
};
```

### 3. å­å·¥ä½œæµ

```typescript
// workflows/definitions/main-workflow.ts
export const mainWorkflow: WorkflowDefinition = {
  id: 'main-workflow',
  name: 'Main Workflow',
  version: '1.0.0',
  
  tasks: [
    {
      id: 'prepare',
      name: 'å‡†å¤‡é˜¶æ®µ',
      type: TaskType.EXECUTOR,
      executor: 'data-preparer'
    },
    {
      id: 'sub-workflow',
      name: 'å­å·¥ä½œæµå¤„ç†',
      type: TaskType.SUB_WORKFLOW,
      workflowId: 'data-processing-v1',
      dependencies: ['prepare'],
      input: {
        sourceData: '${tasks.prepare.output.data}',
        batchSize: '${workflow.variables.batchSize}'
      }
    },
    {
      id: 'cleanup',
      name: 'æ¸…ç†é˜¶æ®µ',
      type: TaskType.EXECUTOR,
      executor: 'data-cleaner',
      dependencies: ['sub-workflow']
    }
  ]
};
```

## âš™ï¸ ä»»åŠ¡æ‰§è¡Œå™¨

### 1. åˆ›å»ºæ‰§è¡Œå™¨

åœ¨ `workflows/executors/` ç›®å½•ä¸‹åˆ›å»ºæ‰§è¡Œå™¨ï¼š

```typescript
// workflows/executors/data-validator.ts
import { TaskExecutor, ExecutionContext, TaskResult } from '@stratix/tasks';

interface ValidatorInput {
  data: any[];
  schema: string;
  strictMode?: boolean;
}

interface ValidatorOutput {
  validRecords: any[];
  invalidRecords: any[];
  validationReport: {
    totalRecords: number;
    validCount: number;
    invalidCount: number;
    errors: string[];
  };
}

export class DataValidatorExecutor implements TaskExecutor<ValidatorInput, ValidatorOutput> {
  name = 'data-validator';
  
  async execute(
    input: ValidatorInput, 
    context: ExecutionContext
  ): Promise<TaskResult<ValidatorOutput>> {
    const { data, schema, strictMode = false } = input;
    const { logger } = context;
    
    logger.info(`å¼€å§‹éªŒè¯ ${data.length} æ¡è®°å½•`);
    
    try {
      const validRecords: any[] = [];
      const invalidRecords: any[] = [];
      const errors: string[] = [];
      
      // è·å–éªŒè¯æ¨¡å¼
      const validationSchema = await this.getValidationSchema(schema);
      
      // éªŒè¯æ¯æ¡è®°å½•
      for (let i = 0; i < data.length; i++) {
        const record = data[i];
        const validation = await this.validateRecord(record, validationSchema, strictMode);
        
        if (validation.isValid) {
          validRecords.push(record);
        } else {
          invalidRecords.push({
            record,
            errors: validation.errors,
            index: i
          });
          errors.push(...validation.errors);
        }
        
        // æŠ¥å‘Šè¿›åº¦
        if (i % 1000 === 0) {
          context.reportProgress((i / data.length) * 100);
        }
      }
      
      const result = {
        validRecords,
        invalidRecords,
        validationReport: {
          totalRecords: data.length,
          validCount: validRecords.length,
          invalidCount: invalidRecords.length,
          errors: [...new Set(errors)] // å»é‡
        }
      };
      
      logger.info(`éªŒè¯å®Œæˆ: ${validRecords.length} æœ‰æ•ˆ, ${invalidRecords.length} æ— æ•ˆ`);
      
      return {
        success: true,
        data: result,
        metadata: {
          executionTime: Date.now() - context.startTime,
          memoryUsage: process.memoryUsage().heapUsed
        }
      };
      
    } catch (error) {
      logger.error('æ•°æ®éªŒè¯å¤±è´¥:', error);
      
      return {
        success: false,
        error: {
          message: 'æ•°æ®éªŒè¯æ‰§è¡Œå¤±è´¥',
          code: 'VALIDATION_EXECUTION_ERROR',
          details: error
        }
      };
    }
  }
  
  private async getValidationSchema(schemaName: string): Promise<any> {
    // ä»é…ç½®æˆ–æ•°æ®åº“è·å–éªŒè¯æ¨¡å¼
    // è¿™é‡Œæ˜¯ç¤ºä¾‹å®ç°
    return {
      type: 'object',
      properties: {
        id: { type: 'string', required: true },
        name: { type: 'string', required: true },
        email: { type: 'string', format: 'email' }
      }
    };
  }
  
  private async validateRecord(record: any, schema: any, strictMode: boolean): Promise<{
    isValid: boolean;
    errors: string[];
  }> {
    // å®ç°å…·ä½“çš„éªŒè¯é€»è¾‘
    const errors: string[] = [];
    
    // ç¤ºä¾‹éªŒè¯é€»è¾‘
    if (!record.id) {
      errors.push('ç¼ºå°‘å¿…éœ€å­—æ®µ: id');
    }
    
    if (!record.name) {
      errors.push('ç¼ºå°‘å¿…éœ€å­—æ®µ: name');
    }
    
    if (record.email && !this.isValidEmail(record.email)) {
      errors.push('é‚®ç®±æ ¼å¼æ— æ•ˆ');
    }
    
    return {
      isValid: errors.length === 0,
      errors
    };
  }
  
  private isValidEmail(email: string): boolean {
    const emailRegex = /^[^\s@]+@[^\s@]+\.[^\s@]+$/;
    return emailRegex.test(email);
  }
}

// å¯¼å‡ºæ‰§è¡Œå™¨ï¼ˆè‡ªåŠ¨å‘ç°æœºåˆ¶ä¼šæ‰«ææ­¤å¯¼å‡ºï¼‰
export default DataValidatorExecutor;
```

### 2. å¼‚æ­¥æ‰§è¡Œå™¨

```typescript
// workflows/executors/file-processor.ts
import { TaskExecutor, ExecutionContext, TaskResult } from '@stratix/tasks';
import { createReadStream } from 'fs';
import { pipeline } from 'stream/promises';

export class FileProcessorExecutor implements TaskExecutor {
  name = 'file-processor';
  
  async execute(input: any, context: ExecutionContext): Promise<TaskResult> {
    const { filePath, outputPath } = input;
    const { logger, signal } = context;
    
    try {
      // æ”¯æŒå–æ¶ˆæ“ä½œ
      if (signal.aborted) {
        throw new Error('ä»»åŠ¡å·²è¢«å–æ¶ˆ');
      }
      
      logger.info(`å¼€å§‹å¤„ç†æ–‡ä»¶: ${filePath}`);
      
      // åˆ›å»ºæ–‡ä»¶æµå¤„ç†ç®¡é“
      await pipeline(
        createReadStream(filePath),
        // è‡ªå®šä¹‰è½¬æ¢æµ
        this.createTransformStream(context),
        // è¾“å‡ºæµ
        this.createOutputStream(outputPath),
        { signal } // æ”¯æŒå–æ¶ˆ
      );
      
      logger.info(`æ–‡ä»¶å¤„ç†å®Œæˆ: ${outputPath}`);
      
      return {
        success: true,
        data: {
          outputPath,
          processedAt: new Date().toISOString()
        }
      };
      
    } catch (error) {
      if (error.name === 'AbortError') {
        logger.warn('æ–‡ä»¶å¤„ç†è¢«å–æ¶ˆ');
        return {
          success: false,
          error: {
            message: 'ä»»åŠ¡è¢«å–æ¶ˆ',
            code: 'TASK_CANCELLED'
          }
        };
      }
      
      throw error;
    }
  }
  
  private createTransformStream(context: ExecutionContext) {
    // å®ç°è‡ªå®šä¹‰è½¬æ¢æµ
    // æ”¯æŒè¿›åº¦æŠ¥å‘Šå’Œå–æ¶ˆæ“ä½œ
  }
  
  private createOutputStream(outputPath: string) {
    // å®ç°è¾“å‡ºæµ
  }
}
```

### 3. æœ‰çŠ¶æ€æ‰§è¡Œå™¨

```typescript
// workflows/executors/batch-processor.ts
export class BatchProcessorExecutor implements TaskExecutor {
  name = 'batch-processor';
  
  async execute(input: any, context: ExecutionContext): Promise<TaskResult> {
    const { items, batchSize = 100 } = input;
    const { logger } = context;
    
    const results = [];
    const batches = this.createBatches(items, batchSize);
    
    for (let i = 0; i < batches.length; i++) {
      const batch = batches[i];
      
      logger.info(`å¤„ç†æ‰¹æ¬¡ ${i + 1}/${batches.length}`);
      
      // å¤„ç†æ‰¹æ¬¡
      const batchResult = await this.processBatch(batch, context);
      results.push(batchResult);
      
      // æŠ¥å‘Šè¿›åº¦
      context.reportProgress(((i + 1) / batches.length) * 100);
      
      // ä¿å­˜ä¸­é—´çŠ¶æ€ï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰
      await context.saveCheckpoint({
        completedBatches: i + 1,
        results: results
      });
      
      // æ£€æŸ¥æ˜¯å¦éœ€è¦æš‚åœ
      if (context.isPaused()) {
        logger.info('ä»»åŠ¡æš‚åœï¼Œä¿å­˜å½“å‰çŠ¶æ€');
        return {
          success: true,
          data: { 
            status: 'paused',
            checkpoint: {
              completedBatches: i + 1,
              totalBatches: batches.length
            }
          }
        };
      }
    }
    
    return {
      success: true,
      data: {
        status: 'completed',
        results,
        totalProcessed: items.length
      }
    };
  }
  
  private createBatches<T>(items: T[], batchSize: number): T[][] {
    const batches: T[][] = [];
    for (let i = 0; i < items.length; i += batchSize) {
      batches.push(items.slice(i, i + batchSize));
    }
    return batches;
  }
  
  private async processBatch(batch: any[], context: ExecutionContext): Promise<any> {
    // å®ç°æ‰¹æ¬¡å¤„ç†é€»è¾‘
    return batch.map(item => ({ ...item, processed: true }));
  }
}
```

## ğŸš€ å¯åŠ¨å’Œç®¡ç†å·¥ä½œæµ

### 1. ç¼–ç¨‹æ–¹å¼å¯åŠ¨

```typescript
// services/workflow-service.ts
import { WorkflowManager } from '@stratix/tasks';

export class MyWorkflowService {
  constructor(private workflowManager: WorkflowManager) {}
  
  async processUserData(userData: any[]): Promise<string> {
    // å¯åŠ¨æ•°æ®å¤„ç†å·¥ä½œæµ
    const instanceId = await this.workflowManager.startWorkflow(
      'data-processing-v1',
      {
        data: userData,
        batchSize: 1000,
        outputFormat: 'json'
      },
      {
        priority: 5,
        correlationId: `user-data-${Date.now()}`,
        timeout: 3600000 // 1å°æ—¶è¶…æ—¶
      }
    );
    
    return instanceId;
  }
  
  async monitorWorkflow(instanceId: string): Promise<void> {
    // ç›‘å¬å·¥ä½œæµçŠ¶æ€å˜åŒ–
    this.workflowManager.onStatusChange(instanceId, (status, instance) => {
      console.log(`å·¥ä½œæµ ${instanceId} çŠ¶æ€å˜åŒ–: ${status}`);
      
      if (status === 'completed') {
        console.log('å·¥ä½œæµå®Œæˆï¼Œç»“æœ:', instance.output);
      } else if (status === 'failed') {
        console.error('å·¥ä½œæµå¤±è´¥:', instance.error);
      }
    });
  }
}
```

### 2. REST API å¯åŠ¨

```bash
# å¯åŠ¨å·¥ä½œæµ
curl -X POST http://localhost:3000/api/workflows/instances \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer your-token" \
  -d '{
    "definitionId": "data-processing-v1",
    "input": {
      "sourceFile": "/data/users.csv",
      "targetTable": "processed_users"
    },
    "priority": 5
  }'
```

### 3. è°ƒåº¦å¯åŠ¨

```typescript
// åˆ›å»ºå®šæ—¶è°ƒåº¦
await workflowManager.createSchedule({
  definitionId: 'data-processing-v1',
  name: 'æ¯æ—¥ç”¨æˆ·æ•°æ®å¤„ç†',
  triggerType: 'cron',
  triggerConfig: {
    cron: '0 2 * * *', // æ¯å¤©å‡Œæ™¨2ç‚¹
    timezone: 'Asia/Shanghai'
  },
  input: {
    sourceFile: '/data/daily/users-${date}.csv',
    targetTable: 'daily_users'
  }
});
```

## ğŸ“Š ç›‘æ§å’Œè°ƒè¯•

### 1. å·¥ä½œæµçŠ¶æ€ç›‘æ§

```typescript
// è·å–å·¥ä½œæµå®ä¾‹çŠ¶æ€
const instance = await workflowManager.getInstance('wf-inst-001');
console.log('å·¥ä½œæµçŠ¶æ€:', instance.status);
console.log('è¿›åº¦:', instance.progress);

// è·å–ä»»åŠ¡åˆ—è¡¨
const tasks = await workflowManager.getTasks('wf-inst-001');
tasks.forEach(task => {
  console.log(`ä»»åŠ¡ ${task.name}: ${task.status}`);
});

// è·å–æ‰§è¡Œå†å²
const history = await workflowManager.getExecutionHistory('wf-inst-001');
history.forEach(event => {
  console.log(`${event.createdAt}: ${event.eventType} - ${event.message}`);
});
```

### 2. å®æ—¶ç›‘æ§

```typescript
// WebSocket å®æ—¶ç›‘æ§
import { WorkflowMonitor } from '@stratix/tasks/client';

const monitor = new WorkflowMonitor({
  baseUrl: 'ws://localhost:3000/api/workflows/monitor'
});

// ç›‘å¬ç‰¹å®šå·¥ä½œæµ
monitor.watch('wf-inst-001', {
  onStatusChange: (status) => {
    console.log('çŠ¶æ€å˜åŒ–:', status);
  },
  onTaskCompleted: (task) => {
    console.log('ä»»åŠ¡å®Œæˆ:', task.name);
  },
  onProgress: (progress) => {
    console.log('è¿›åº¦æ›´æ–°:', progress.percentage + '%');
  }
});
```

### 3. æ€§èƒ½ç›‘æ§

```typescript
// è·å–æ€§èƒ½æŒ‡æ ‡
const metrics = await workflowManager.getPerformanceMetrics({
  definitionId: 'data-processing-v1',
  period: '7d'
});

console.log('å¹³å‡æ‰§è¡Œæ—¶é—´:', metrics.averageDuration);
console.log('æˆåŠŸç‡:', metrics.successRate);
console.log('ååé‡:', metrics.throughput);
```

## ğŸ”§ é«˜çº§åŠŸèƒ½

### 1. è‡ªå®šä¹‰ä¸­é—´ä»¶

```typescript
// workflows/middleware/auth-middleware.ts
import { WorkflowMiddleware, ExecutionContext } from '@stratix/tasks';

export class AuthMiddleware implements WorkflowMiddleware {
  async beforeWorkflow(context: ExecutionContext): Promise<void> {
    // å·¥ä½œæµæ‰§è¡Œå‰çš„è®¤è¯æ£€æŸ¥
    const { input, variables } = context;

    if (!input.userId) {
      throw new Error('ç¼ºå°‘ç”¨æˆ·ID');
    }

    const user = await this.getUserById(input.userId);
    if (!user) {
      throw new Error('ç”¨æˆ·ä¸å­˜åœ¨');
    }

    // å°†ç”¨æˆ·ä¿¡æ¯æ·»åŠ åˆ°ä¸Šä¸‹æ–‡
    context.setVariable('currentUser', user);
  }

  async beforeTask(taskId: string, context: ExecutionContext): Promise<void> {
    // ä»»åŠ¡æ‰§è¡Œå‰çš„æƒé™æ£€æŸ¥
    const user = context.getVariable('currentUser');
    const hasPermission = await this.checkTaskPermission(user, taskId);

    if (!hasPermission) {
      throw new Error(`ç”¨æˆ· ${user.id} æ²¡æœ‰æ‰§è¡Œä»»åŠ¡ ${taskId} çš„æƒé™`);
    }
  }

  async afterTask(taskId: string, result: any, context: ExecutionContext): Promise<void> {
    // ä»»åŠ¡æ‰§è¡Œåçš„å®¡è®¡æ—¥å¿—
    const user = context.getVariable('currentUser');
    await this.logTaskExecution(user.id, taskId, result);
  }

  private async getUserById(userId: string): Promise<any> {
    // å®ç°ç”¨æˆ·æŸ¥è¯¢é€»è¾‘
  }

  private async checkTaskPermission(user: any, taskId: string): Promise<boolean> {
    // å®ç°æƒé™æ£€æŸ¥é€»è¾‘
  }

  private async logTaskExecution(userId: string, taskId: string, result: any): Promise<void> {
    // å®ç°å®¡è®¡æ—¥å¿—è®°å½•
  }
}
```

### 2. è‡ªå®šä¹‰æ¡ä»¶è¡¨è¾¾å¼

```typescript
// workflows/conditions/custom-conditions.ts
import { ConditionEvaluator } from '@stratix/tasks';

export class CustomConditionEvaluator implements ConditionEvaluator {
  evaluate(expression: string, context: any): boolean {
    // æ”¯æŒè‡ªå®šä¹‰æ¡ä»¶è¯­æ³•
    switch (expression) {
      case 'is_business_hours':
        return this.isBusinessHours();

      case 'is_weekend':
        return this.isWeekend();

      case 'file_size_large':
        return context.input.fileSize > 10 * 1024 * 1024; // 10MB

      default:
        // ä½¿ç”¨é»˜è®¤çš„è¡¨è¾¾å¼æ±‚å€¼å™¨
        return this.evaluateDefaultExpression(expression, context);
    }
  }

  private isBusinessHours(): boolean {
    const now = new Date();
    const hour = now.getHours();
    const day = now.getDay();

    // å·¥ä½œæ—¥çš„9-18ç‚¹
    return day >= 1 && day <= 5 && hour >= 9 && hour < 18;
  }

  private isWeekend(): boolean {
    const day = new Date().getDay();
    return day === 0 || day === 6;
  }

  private evaluateDefaultExpression(expression: string, context: any): boolean {
    // å®ç°é»˜è®¤è¡¨è¾¾å¼æ±‚å€¼é€»è¾‘
    // æ”¯æŒ JavaScript è¡¨è¾¾å¼ã€JSONPath ç­‰
    return true;
  }
}
```
