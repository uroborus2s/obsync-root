/**
 * èŠ‚ç‚¹æ‰§è¡ŒæœåŠ¡å®ç°
 *
 * å®ç°å„ç§ç±»å‹èŠ‚ç‚¹çš„æ‰§è¡Œé€»è¾‘
 * ç‰ˆæœ¬: v3.0.0-refactored
 */

import type { Logger } from '@stratix/core';
import type { DatabaseAPI } from '@stratix/database';
import { sleep } from '@stratix/utils/async';
import type {
  INodeExecutionService,
  INodeInstanceRepository,
  ITemplateService,
  IWorkflowDefinitionService,
  IWorkflowInstanceService
} from '../interfaces/index.js';
import { getExecutor } from '../registerTask.js';
import type {
  ExecutionResult,
  LoopProgress,
  ServiceResult,
  WorkflowInstance
} from '../types/business.js';
import {
  NewWorkflowNodeInstance,
  WorkflowDefinitionTable
} from '../types/database.js';
import type { NodeInstance } from '../types/unified-node.js';
import {
  ExecutionContext,
  NodeDefinition,
  SubprocessNodeDefinition,
  WorkflowDefinitionData
} from '../types/workflow.js';

/**
 * èŠ‚ç‚¹æ‰§è¡ŒæœåŠ¡å®ç°
 */
export default class NodeExecutionService implements INodeExecutionService {
  constructor(
    private readonly nodeInstanceRepository: INodeInstanceRepository,
    private readonly logger: Logger,
    private readonly databaseApi: DatabaseAPI,
    private readonly templateService: ITemplateService,
    private readonly workflowInstanceService: IWorkflowInstanceService,
    private readonly workflowDefinitionService: IWorkflowDefinitionService
  ) {}

  /**
   * æ‰§è¡Œç®€å•æ“ä½œèŠ‚ç‚¹
   *
   * 1. è·å–å·¥ä½œæµå®ä¾‹å’Œæ„å»ºå®Œæ•´çš„å˜é‡ä¸Šä¸‹æ–‡
   * 2. æ‰§è¡ŒåŸºç¡€æ“ä½œèŠ‚ç‚¹é€»è¾‘
   * 3. è·å–å¯¹åº”çš„æ‰§è¡Œå™¨
   * 4. è°ƒç”¨æ‰§è¡Œå™¨æ‰§è¡Œä¸šåŠ¡é€»è¾‘
   * 5. è¿”å›æ‰§è¡Œç»“æœ
   */
  async executeSimpleNode(
    executionContext: ExecutionContext
  ): Promise<ServiceResult<ExecutionResult>> {
    const { nodeInstance, workflowInstance } = executionContext;
    try {
      this.logger.info('Executing simple node', {
        nodeId: nodeInstance.nodeId,
        workflowInstanceId: workflowInstance.id
      });

      const startTime = Date.now();

      // æ›´æ–°èŠ‚ç‚¹çŠ¶æ€ä¸ºæ‰§è¡Œä¸­
      await this.updateNodeStatus(nodeInstance.id, 'running');

      // è·å–æ‰§è¡Œå™¨
      if (!nodeInstance.executor) {
        return {
          success: false,
          error: 'No executor specified for node'
        };
      }

      const executor = getExecutor(nodeInstance.executor);
      if (!executor) {
        return {
          success: false,
          error: `Executor not found: ${nodeInstance.executor}`
        };
      }
      // æ‰§è¡Œä»»åŠ¡
      const result = await executor.execute(executionContext);
      const duration = Date.now() - startTime;

      if (result.success) {
        // æ›´æ–°èŠ‚ç‚¹çŠ¶æ€ä¸ºå®Œæˆ
        await this.updateNodeStatus(nodeInstance.id, 'completed');
        await this.nodeInstanceRepository.updateNodeInstance(nodeInstance.id, {
          output_data: result.data,
          completed_at: new Date(),
          duration_ms: duration
        });

        return {
          success: true,
          data: {
            success: true,
            data: result.data,
            duration
          }
        };
      } else {
        // æ›´æ–°èŠ‚ç‚¹çŠ¶æ€ä¸ºå¤±è´¥
        await this.updateNodeStatus(
          nodeInstance.id,
          'failed',
          result.error,
          result
        );

        return {
          success: false,
          error: result.error || 'Task execution failed',
          errorDetails: result
        };
      }
    } catch (error) {
      this.logger.error('Failed to execute simple node', {
        error,
        nodeInstance
      });
      await this.updateNodeStatus(
        nodeInstance.id,
        'failed',
        'Execution error',
        error
      );

      return {
        success: false,
        error: 'Failed to execute simple node',
        errorDetails: error
      };
    }
  }

  /**
   * æ‰§è¡Œå¾ªç¯èŠ‚ç‚¹
   *
   * ç®€åŒ–çš„ä¸¤é˜¶æ®µæ‰§è¡Œæµç¨‹ï¼š
   *
   * 1. çŠ¶æ€åˆ¤æ–­ä¸åˆ›å»ºæµç¨‹ï¼š
   *    - æ£€æŸ¥å½“å‰èŠ‚ç‚¹çš„progress.status
   *    - å¦‚æœçŠ¶æ€æ˜¯'creating'ï¼Œæ‰§è¡Œå­èŠ‚ç‚¹åˆ›å»ºæµç¨‹
   *    - ä½¿ç”¨æ•°æ®åº“äº‹åŠ¡æ‰¹é‡åˆ›å»ºæ‰€æœ‰å­èŠ‚ç‚¹å®ä¾‹
   *    - åœ¨åŒä¸€äº‹åŠ¡ä¸­å°†çˆ¶èŠ‚ç‚¹çŠ¶æ€æ›´æ–°ä¸º'executing'
   *    - ç›´æ¥ä¿®æ”¹æœ¬åœ°progresså¯¹è±¡çŠ¶æ€ä¸º'executing'
   *
   * 2. çŠ¶æ€åˆ¤æ–­ä¸æ‰§è¡Œæµç¨‹ï¼š
   *    - åˆ›å»ºæµç¨‹å®Œæˆåï¼Œç«‹å³æ£€æŸ¥progress.statusæ˜¯å¦ä¸º'executing'
   *    - å¦‚æœæ˜¯'executing'çŠ¶æ€ï¼Œè¿›å…¥å­èŠ‚ç‚¹æ‰§è¡Œæµç¨‹
   *    - æ‰§è¡Œæ‰€æœ‰å¾…å¤„ç†çš„å­èŠ‚ç‚¹
   *
   * å…³é”®ç‰¹æ€§ï¼š
   * - ç®€å•çš„if-elseé€»è¾‘ï¼Œé¿å…åµŒå¥—çš„å¼‚æ­¥è°ƒç”¨
   * - ç§»é™¤å¤æ‚çš„çŠ¶æ€åŒæ­¥é€»è¾‘ï¼ˆé‡æ–°è·å–èŠ‚ç‚¹å®ä¾‹ç­‰ï¼‰
   * - åˆ›å»ºå’Œæ‰§è¡Œåœ¨åŒä¸€ä¸ªæ–¹æ³•è°ƒç”¨ä¸­é¡ºåºå®Œæˆ
   * - æ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼šç³»ç»Ÿé‡å¯åèƒ½ä»æ­£ç¡®æ­¥éª¤ç»§ç»­æ‰§è¡Œ
   */
  async executeLoopNode(
    executionContext: ExecutionContext
  ): Promise<ServiceResult<ExecutionResult>> {
    const { nodeInstance } = executionContext;
    try {
      this.logger.info('Executing loop node', {
        nodeId: nodeInstance.nodeId,
        workflowInstanceId: nodeInstance.workflowInstanceId,
        currentStatus: nodeInstance.status
      });

      // è·å–å½“å‰å¾ªç¯æ‰§è¡Œè¿›åº¦ï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ 
      let progress: LoopProgress = nodeInstance.loopProgress || {
        status: 'creating',
        totalCount: 0,
        completedCount: 0,
        failedCount: 0
      };

      this.logger.debug('Loop node progress status', {
        nodeId: nodeInstance.nodeId,
        progressStatus: progress.status,
        totalCount: progress.totalCount,
        completedCount: progress.completedCount,
        failedCount: progress.failedCount
      });

      // ç¬¬ä¸€æ­¥ï¼šå­èŠ‚ç‚¹åˆ›å»ºé˜¶æ®µ
      if (progress.status === 'creating') {
        this.logger.info('Starting child node creation phase', {
          nodeId: nodeInstance.nodeId
        });

        const creationResult =
          await this.executeChildNodeCreationPhase(executionContext);
        if (!creationResult.success) {
          return creationResult;
        }

        // ç›´æ¥æ›´æ–°æœ¬åœ°progresså¯¹è±¡çŠ¶æ€ï¼Œé¿å…é‡æ–°æŸ¥è¯¢æ•°æ®åº“
        progress = {
          status: 'executing',
          totalCount: creationResult.data?.data?.totalCount || 0,
          completedCount: 0,
          failedCount: 0
        };

        this.logger.info(
          'Child nodes created successfully, proceeding to execution phase',
          {
            nodeId: nodeInstance.nodeId,
            totalCount: progress.totalCount
          }
        );
      }

      // ç¬¬äºŒæ­¥ï¼šå­èŠ‚ç‚¹æ‰§è¡Œé˜¶æ®µ
      if (progress.status === 'executing') {
        this.logger.info('Starting child node execution phase', {
          nodeId: nodeInstance.nodeId,
          totalCount: progress.totalCount,
          completedCount: progress.completedCount,
          failedCount: progress.failedCount
        });

        return await this.executeChildNodeExecutionPhase(
          executionContext,
          progress
        );
      }

      // å·²å®ŒæˆçŠ¶æ€
      if (progress.status === 'completed') {
        this.logger.info('Loop node already completed', {
          nodeId: nodeInstance.nodeId,
          progress
        });
        return {
          success: true,
          data: {
            success: true,
            data: { status: 'completed', progress }
          }
        };
      }

      // æœªçŸ¥çŠ¶æ€
      return {
        success: false,
        error: `Unknown loop progress status: ${progress.status}`
      };
    } catch (error) {
      this.logger.error('Failed to execute loop node', {
        error,
        nodeId: nodeInstance.nodeId,
        workflowInstanceId: nodeInstance.workflowInstanceId
      });

      await this.updateNodeStatus(
        nodeInstance.id,
        'failed',
        'Loop execution error',
        error
      );

      return {
        success: false,
        error: 'Failed to execute loop node',
        errorDetails: error
      };
    }
  }

  /**
   * ç¬¬ä¸€æ­¥ï¼šå­èŠ‚ç‚¹åˆ›å»ºé˜¶æ®µ
   *
   * åŠŸèƒ½ï¼š
   * 1. æ‰§è¡Œæ•°æ®è·å–å™¨æ‰§è¡Œå™¨è·å–å¾ªç¯æ•°æ®
   * 2. ä½¿ç”¨æ•°æ®åº“äº‹åŠ¡ç¡®ä¿åŸå­æ€§æ“ä½œï¼š
   *    - æ‰¹é‡åˆ›å»ºæ‰€æœ‰å­èŠ‚ç‚¹è®°å½•
   *    - åœ¨åŒä¸€äº‹åŠ¡ä¸­å°†çˆ¶èŠ‚ç‚¹çŠ¶æ€æ›´æ–°ä¸º'executing'
   *    - åœ¨åŒä¸€äº‹åŠ¡ä¸­å°†progress.statusæ›´æ–°ä¸º'executing'
   * 3. ç¡®ä¿åœ¨è¿™ä¸ªé˜¶æ®µä¸æ‰§è¡Œä»»ä½•å­èŠ‚ç‚¹ï¼Œåªè´Ÿè´£èŠ‚ç‚¹å®ä¾‹çš„åˆ›å»º
   */
  private async executeChildNodeCreationPhase(
    executionContext: ExecutionContext
  ): Promise<ServiceResult<ExecutionResult>> {
    const { nodeInstance, nodeDefinition } = executionContext;

    this.logger.info('Starting child node creation phase', {
      nodeId: nodeInstance.nodeId,
      workflowInstanceId: nodeInstance.workflowInstanceId
    });

    try {
      // 1. æ‰§è¡Œæ•°æ®è·å–å™¨æ‰§è¡Œå™¨
      const dataFetchResult = await this.fetchLoopData(executionContext);
      if (!dataFetchResult.success) {
        return {
          success: false,
          error: dataFetchResult.error,
          errorDetails: dataFetchResult.errorDetails
        };
      }

      const { loopData, totalCount } = dataFetchResult.data!;

      // 2. è·å–å­èŠ‚ç‚¹å®šä¹‰
      const childNodeDefinition = this.getChildNodeDefinition(nodeDefinition);
      if (!childNodeDefinition) {
        return {
          success: false,
          error:
            'No child node definition found in loop node definition. Loop node must have either "node" or "taskTemplate" property.'
        };
      }

      // 3. ä½¿ç”¨æ•°æ®åº“äº‹åŠ¡ç¡®ä¿åŸå­æ€§æ“ä½œ
      const transactionResult = await this.executeChildNodeCreationTransaction(
        executionContext,
        loopData,
        totalCount,
        childNodeDefinition
      );

      if (!transactionResult.success) {
        return transactionResult;
      }

      this.logger.info('Child node creation phase completed successfully', {
        nodeId: nodeInstance.nodeId,
        totalCount,
        childNodeType: childNodeDefinition.nodeType
      });

      return {
        success: true,
        data: {
          success: true,
          data: {
            status: 'child_nodes_created',
            phase: 'creation_completed',
            totalCount,
            childNodeDefinition: {
              nodeType: childNodeDefinition.nodeType,
              nodeName: childNodeDefinition.nodeName
            }
          }
        }
      };
    } catch (error) {
      this.logger.error('Child node creation phase failed', {
        error,
        nodeId: nodeInstance.nodeId,
        workflowInstanceId: nodeInstance.workflowInstanceId
      });

      await this.updateNodeStatus(
        nodeInstance.id,
        'failed',
        'Child node creation failed',
        error
      );

      return {
        success: false,
        error: 'Child node creation phase failed',
        errorDetails: error
      };
    }
  }

  /**
   * ç¬¬äºŒæ­¥ï¼šå­èŠ‚ç‚¹æ‰§è¡Œé˜¶æ®µ
   *
   * åŠŸèƒ½ï¼š
   * 1. æ£€æŸ¥å¾ªç¯èŠ‚ç‚¹çš„å½“å‰çŠ¶æ€ï¼Œç¡®è®¤å­èŠ‚ç‚¹å·²åˆ›å»ºå®Œæˆ
   * 2. æ ¹æ®å­èŠ‚ç‚¹çš„æ‰§è¡ŒçŠ¶æ€ï¼ˆæœªå¼€å§‹ã€è¿›è¡Œä¸­ã€å·²å®Œæˆã€å¤±è´¥ç­‰ï¼‰æ¥å†³å®šæ‰§è¡Œç­–ç•¥
   * 3. æŒ‰ç…§å¾ªç¯èŠ‚ç‚¹çš„é…ç½®ï¼ˆä¸²è¡Œ/å¹¶è¡Œæ‰§è¡Œï¼‰æ¥è°ƒåº¦å­èŠ‚ç‚¹çš„æ‰§è¡Œ
   * 4. å®ç°é€‚å½“çš„é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶
   */
  private async executeChildNodeExecutionPhase(
    executionContext: ExecutionContext,
    progress: LoopProgress
  ): Promise<ServiceResult<ExecutionResult>> {
    const { nodeInstance } = executionContext;

    this.logger.info('Starting child node execution phase', {
      nodeId: nodeInstance.nodeId,
      workflowInstanceId: nodeInstance.workflowInstanceId,
      totalCount: progress.totalCount,
      completedCount: progress.completedCount,
      failedCount: progress.failedCount
    });

    try {
      // 1. æ£€æŸ¥å¾ªç¯èŠ‚ç‚¹çŠ¶æ€ï¼Œç¡®è®¤å­èŠ‚ç‚¹å·²åˆ›å»ºå®Œæˆ
      if (progress.status !== 'executing') {
        return {
          success: false,
          error: `Invalid progress status for execution phase: ${progress.status}. Expected 'executing'.`
        };
      }

      // 2. è·å–æ‰€æœ‰æœªæ‰§è¡Œçš„å­èŠ‚ç‚¹
      const pendingChildrenResult =
        await this.nodeInstanceRepository.findPendingChildNodes(
          nodeInstance.id
        );
      if (!pendingChildrenResult.success) {
        return {
          success: false,
          error: 'Failed to get pending child nodes',
          errorDetails: pendingChildrenResult.error
        };
      }

      const pendingChildren = pendingChildrenResult.data || [];

      this.logger.debug('Found pending child nodes for execution', {
        nodeId: nodeInstance.nodeId,
        pendingChildrenCount: pendingChildren.length,
        totalCount: progress.totalCount
      });

      // 3. å¦‚æœæ²¡æœ‰å¾…æ‰§è¡Œçš„å­èŠ‚ç‚¹ï¼Œæ£€æŸ¥æ˜¯å¦æ‰€æœ‰å­èŠ‚ç‚¹éƒ½å·²å®Œæˆ
      if (pendingChildren.length === 0) {
        return await this.handleAllChildNodesCompleted(nodeInstance, progress);
      }

      // 4. æ ¹æ®é…ç½®å†³å®šæ‰§è¡Œç­–ç•¥ï¼ˆä¸²è¡Œ/å¹¶è¡Œï¼‰
      const executionMode = nodeInstance.executorConfig?.parallel
        ? 'parallel'
        : 'serial';

      this.logger.info('Executing child nodes', {
        nodeId: nodeInstance.nodeId,
        executionMode,
        pendingChildrenCount: pendingChildren.length
      });

      if (executionMode === 'parallel') {
        return await this.executeChildNodesInParallel(
          executionContext,
          pendingChildren,
          progress
        );
      } else {
        return await this.executeChildNodesInSerial(
          executionContext,
          pendingChildren,
          progress
        );
      }
    } catch (error) {
      this.logger.error('Child node execution phase failed', {
        error,
        nodeId: nodeInstance.nodeId,
        workflowInstanceId: nodeInstance.workflowInstanceId
      });

      await this.updateNodeStatus(
        nodeInstance.id,
        'failed',
        'Child node execution failed',
        error
      );

      return {
        success: false,
        error: 'Child node execution phase failed',
        errorDetails: error
      };
    }
  }

  /**
   * è·å–å¾ªç¯æ•°æ®
   * æ‰§è¡Œæ•°æ®è·å–å™¨æ‰§è¡Œå™¨è·å–å¾ªç¯æ•°æ®
   */
  private async fetchLoopData(
    executionContext: ExecutionContext
  ): Promise<ServiceResult<{ loopData: any[]; totalCount: number }>> {
    const { nodeInstance } = executionContext;

    // 1. éªŒè¯æ‰§è¡Œå™¨
    if (!nodeInstance.executor) {
      return {
        success: false,
        error: 'No data fetcher executor specified for loop node'
      };
    }

    const executor = getExecutor(nodeInstance.executor);
    if (!executor) {
      return {
        success: false,
        error: `Data fetcher executor not found: ${nodeInstance.executor}`
      };
    }

    this.logger.debug('Fetching loop data', {
      nodeId: nodeInstance.nodeId,
      executor: nodeInstance.executor
    });

    // 2. æ‰§è¡Œæ•°æ®è·å–å™¨
    const dataResult = await executor.execute(executionContext);
    if (!dataResult.success) {
      return {
        success: false,
        error: 'Failed to fetch loop data',
        errorDetails: dataResult
      };
    }

    // 3. å¤„ç†è¿”å›çš„æ•°æ®
    const loopData = Array.isArray(dataResult.data.items)
      ? dataResult.data.items
      : [dataResult.data.items];
    const totalCount = loopData.length;

    this.logger.info('Loop data fetched successfully', {
      nodeId: nodeInstance.nodeId,
      totalCount,
      executor: nodeInstance.executor
    });

    return {
      success: true,
      data: { loopData, totalCount }
    };
  }

  /**
   * è·å–å­èŠ‚ç‚¹å®šä¹‰
   * ä»å¾ªç¯èŠ‚ç‚¹å®šä¹‰ä¸­æå–å­èŠ‚ç‚¹å®šä¹‰
   */
  private getChildNodeDefinition(
    nodeDefinition: NodeDefinition
  ): NodeDefinition | null {
    const loopDefinition = nodeDefinition as any; // LoopNodeDefinition
    const childNodeDefinition =
      loopDefinition.node || loopDefinition.taskTemplate;

    if (!childNodeDefinition) {
      this.logger.error('No child node definition found', {
        nodeDefinition: loopDefinition,
        hasNode: !!loopDefinition.node,
        hasTaskTemplate: !!loopDefinition.taskTemplate
      });
      return null;
    }

    this.logger.debug('Child node definition found', {
      nodeType: childNodeDefinition.nodeType,
      executor: childNodeDefinition.executor,
      nodeName: childNodeDefinition.nodeName,
      hasInputData: !!childNodeDefinition.inputData
    });

    return childNodeDefinition;
  }

  /**
   * æ‰§è¡Œå­èŠ‚ç‚¹åˆ›å»ºäº‹åŠ¡
   * ä½¿ç”¨æ•°æ®åº“äº‹åŠ¡ç¡®ä¿åŸå­æ€§æ“ä½œï¼š
   * 1. æ‰¹é‡åˆ›å»ºæ‰€æœ‰å­èŠ‚ç‚¹è®°å½•
   * 2. åœ¨åŒä¸€äº‹åŠ¡ä¸­å°†çˆ¶èŠ‚ç‚¹çŠ¶æ€æ›´æ–°ä¸º'executing'
   * 3. åœ¨åŒä¸€äº‹åŠ¡ä¸­å°†progress.statusæ›´æ–°ä¸º'executing'
   */
  private async executeChildNodeCreationTransaction(
    executionContext: ExecutionContext,
    loopData: any[],
    totalCount: number,
    childNodeDefinition: any
  ): Promise<ServiceResult<ExecutionResult>> {
    const { nodeInstance } = executionContext;
    this.logger.info('Starting child node creation transaction', {
      nodeId: nodeInstance.nodeId,
      totalCount,
      childNodeType: childNodeDefinition.nodeType
    });

    try {
      const childNodeInstances = [] as NewWorkflowNodeInstance[];
      for (let index = 0; index < loopData.length; index += 1) {
        const data = loopData[index];
        const resolvedConfig = await this.resolveTemplateVariables(
          executionContext,
          data,
          childNodeDefinition.inputData
        );
        childNodeInstances.push({
          workflow_instance_id: nodeInstance.workflowInstanceId,
          node_id: `${nodeInstance.nodeId}_child_${index}`,
          node_name:
            childNodeDefinition.nodeName ||
            `${nodeInstance.nodeName} - Item ${index + 1}`,
          node_description:
            childNodeDefinition.nodeDescription ||
            `Child node ${index + 1} of ${nodeInstance.nodeName}`,
          node_type: childNodeDefinition.nodeType || 'simple',
          executor: childNodeDefinition.executor || null,
          status: 'pending' as const,
          input_data: {
            // åˆå¹¶å­èŠ‚ç‚¹å®šä¹‰ä¸­çš„è¾“å…¥æ•°æ®
            ...resolvedConfig,
            // åˆå¹¶å¾ªç¯æ•°æ®
            iterationIndex: index,
            iterationData: data,
            parentNodeId: nodeInstance.nodeId
          },
          output_data: null,
          timeout_seconds: childNodeDefinition.timeoutSeconds || null,
          retry_delay_seconds: childNodeDefinition.retryDelaySeconds || null,
          execution_condition: childNodeDefinition.condition || null,
          error_message: null,
          error_details: null,
          started_at: null,
          completed_at: null,
          duration_ms: null,
          retry_count: 0,
          max_retries: childNodeDefinition.maxRetries || 3,
          parent_node_id: nodeInstance.id,
          child_index: index,
          loop_progress: null,
          loop_total_count: null,
          loop_completed_count: 0,
          parallel_group_id: null,
          parallel_index: null
        });
      }

      // çœŸæ­£çš„æ•°æ®åº“äº‹åŠ¡å®ç°ï¼šç¡®ä¿ACIDç‰¹æ€§
      const updatedProgress: LoopProgress = {
        status: 'executing',
        totalCount,
        completedCount: 0,
        failedCount: 0
      };

      // ğŸ¯ ä½¿ç”¨æ–°çš„æ— æ„Ÿäº‹åŠ¡æ”¯æŒ
      const transactionResult = await this.databaseApi.transaction(async () => {
        this.logger.debug(
          'Starting database transaction for child node creation',
          {
            nodeId: executionContext.nodeInstance.nodeId,
            totalCount
          }
        );

        // 1. åœ¨äº‹åŠ¡ä¸­æ‰¹é‡åˆ›å»ºå­èŠ‚ç‚¹å®ä¾‹
        // Repository ä¼šè‡ªåŠ¨æ£€æµ‹å¹¶ä½¿ç”¨å½“å‰äº‹åŠ¡
        const createResult =
          await this.nodeInstanceRepository.createMany(childNodeInstances);
        if (!createResult.success) {
          throw new Error(
            `Failed to create child node instances: ${createResult.error}`
          );
        }

        this.logger.debug('Child nodes created in transaction', {
          nodeId: nodeInstance.nodeId,
          createdCount: createResult.data?.length || 0
        });

        // 2. åœ¨åŒä¸€äº‹åŠ¡ä¸­æ›´æ–°çˆ¶å¾ªç¯èŠ‚ç‚¹çš„çŠ¶æ€
        // Repository ä¼šè‡ªåŠ¨æ£€æµ‹å¹¶ä½¿ç”¨å½“å‰äº‹åŠ¡
        const updateResult =
          await this.nodeInstanceRepository.updateLoopProgress(
            nodeInstance.id,
            updatedProgress,
            0
          );

        if (!updateResult.success) {
          throw new Error(
            `Failed to update loop progress: ${updateResult.error}`
          );
        }

        this.logger.debug('Loop progress updated in transaction', {
          nodeId: nodeInstance.nodeId,
          progress: updatedProgress
        });

        return {
          childNodes: createResult.data,
          progress: updatedProgress
        };
      });

      if (!transactionResult.success) {
        throw new Error(
          `Database transaction failed: ${transactionResult.error}`
        );
      }

      const { childNodes, progress } = transactionResult.data;

      this.logger.info(
        'Child node creation transaction completed successfully',
        {
          nodeId: nodeInstance.nodeId,
          totalCount,
          createdChildNodes: childNodes?.length || 0
        }
      );

      return {
        success: true,
        data: {
          success: true,
          data: {
            totalCount,
            childNodes,
            progress
          }
        }
      };
    } catch (error) {
      this.logger.error('Child node creation transaction failed', {
        error,
        nodeId: nodeInstance.nodeId,
        totalCount
      });

      return {
        success: false,
        error: 'Child node creation transaction failed',
        errorDetails: error
      };
    }
  }

  /**
   * å¤„ç†æ‰€æœ‰å­èŠ‚ç‚¹å·²å®Œæˆçš„æƒ…å†µ
   */
  private async handleAllChildNodesCompleted(
    nodeInstance: any,
    progress: LoopProgress
  ): Promise<ServiceResult<ExecutionResult>> {
    this.logger.info('All child nodes completed, finalizing loop node', {
      nodeId: nodeInstance.nodeId,
      totalCount: progress.totalCount,
      completedCount: progress.completedCount,
      failedCount: progress.failedCount
    });

    // æ›´æ–°å¾ªç¯èŠ‚ç‚¹çŠ¶æ€ä¸ºå®Œæˆ
    await this.updateNodeStatus(nodeInstance.id, 'completed');

    const finalProgress: LoopProgress = {
      ...progress,
      status: 'completed'
    };

    await this.nodeInstanceRepository.updateLoopProgress(
      nodeInstance.id,
      finalProgress,
      progress.completedCount
    );

    return {
      success: true,
      data: {
        success: true,
        data: {
          status: 'completed',
          progress: finalProgress,
          summary: {
            totalCount: progress.totalCount,
            completedCount: progress.completedCount,
            failedCount: progress.failedCount,
            successRate:
              progress.totalCount > 0
                ? (
                    (progress.completedCount / progress.totalCount) *
                    100
                  ).toFixed(2) + '%'
                : '0%'
          }
        }
      }
    };
  }

  /**
   * å¹¶è¡Œæ‰§è¡Œå­èŠ‚ç‚¹
   */
  private async executeChildNodesInParallel(
    executionContext: ExecutionContext,
    pendingChildren: any[],
    progress: LoopProgress
  ): Promise<ServiceResult<ExecutionResult>> {
    const { nodeInstance, nodeDefinition } = executionContext;

    this.logger.info('Executing child nodes in parallel', {
      nodeId: nodeInstance.nodeId,
      pendingChildrenCount: pendingChildren.length
    });

    // è·å–å­èŠ‚ç‚¹å®šä¹‰
    const childNodeDefinition = this.getChildNodeDefinition(nodeDefinition);
    if (!childNodeDefinition) {
      return {
        success: false,
        error: 'No child node definition found for parallel execution'
      };
    }

    // å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰å­èŠ‚ç‚¹
    const childResults = await Promise.allSettled(
      pendingChildren.map((child) => {
        const childContext: ExecutionContext = {
          ...executionContext,
          nodeInstance: this.mapToBusinessModel(child),
          nodeDefinition: childNodeDefinition
        };
        return this.executeNode(childContext);
      })
    );

    let completedCount = progress.completedCount;
    let failedCount = progress.failedCount;

    childResults.forEach((result) => {
      if (result.status === 'fulfilled' && result.value.success) {
        completedCount++;
      } else {
        failedCount++;
      }
    });

    const updatedProgress: LoopProgress = {
      ...progress,
      completedCount,
      failedCount
    };

    await this.nodeInstanceRepository.updateLoopProgress(
      nodeInstance.id,
      updatedProgress,
      completedCount
    );

    this.logger.info('Parallel execution completed', {
      nodeId: nodeInstance.nodeId,
      completedCount,
      failedCount,
      totalProcessed: pendingChildren.length
    });

    return {
      success: true,
      data: {
        success: true,
        data: {
          status: 'executing',
          progress: updatedProgress,
          executionMode: 'parallel',
          processedCount: pendingChildren.length
        }
      }
    };
  }

  /**
   * ä¸²è¡Œæ‰§è¡Œå­èŠ‚ç‚¹
   */
  private async executeChildNodesInSerial(
    executionContext: ExecutionContext,
    pendingChildren: any[],
    progress: LoopProgress
  ): Promise<ServiceResult<ExecutionResult>> {
    const { nodeInstance, nodeDefinition } = executionContext;

    this.logger.info('Executing child nodes in serial', {
      nodeId: nodeInstance.nodeId,
      pendingChildrenCount: pendingChildren.length
    });

    // è·å–å­èŠ‚ç‚¹å®šä¹‰
    const childNodeDefinition = this.getChildNodeDefinition(nodeDefinition);
    if (!childNodeDefinition) {
      return {
        success: false,
        error: 'No child node definition found for serial execution'
      };
    }

    let completedCount = progress.completedCount;
    let failedCount = progress.failedCount;
    const childResults: any[] = [];

    // é€ä¸ªä¸²è¡Œæ‰§è¡Œå­èŠ‚ç‚¹
    for (let i = 0; i < pendingChildren.length; i++) {
      const child = pendingChildren[i];

      this.logger.debug('Executing child node in serial mode', {
        parentNodeId: nodeInstance.nodeId,
        childNodeId: child.node_id,
        childIndex: i + 1,
        totalChildren: pendingChildren.length
      });

      const childContext = {
        ...executionContext,
        config: child.input_data,
        nodeInstance: this.mapToBusinessModel(child),
        nodeDefinition: childNodeDefinition
      };

      try {
        const childResult = await this.executeNode(childContext);
        childResults.push(childResult);

        if (childResult.success) {
          completedCount++;
          this.logger.debug('Child node completed successfully', {
            parentNodeId: nodeInstance.nodeId,
            childNodeId: child.node_id,
            completedCount
          });
        } else {
          failedCount++;
          this.logger.warn('Child node execution failed', {
            parentNodeId: nodeInstance.nodeId,
            childNodeId: child.node_id,
            error: childResult.error,
            failedCount
          });

          // æ ¹æ®é”™è¯¯å¤„ç†ç­–ç•¥å†³å®šæ˜¯å¦ç»§ç»­
          const errorHandling =
            nodeInstance.executorConfig?.errorHandling || 'continue';
          if (errorHandling === 'stop') {
            this.logger.warn(
              'Stopping serial execution due to child node failure',
              {
                parentNodeId: nodeInstance.nodeId,
                failedChildNodeId: child.node_id,
                errorHandling
              }
            );
            break;
          }
        }

        // æ›´æ–°è¿›åº¦ï¼ˆæ¯æ‰§è¡Œå®Œä¸€ä¸ªå­èŠ‚ç‚¹å°±æ›´æ–°ä¸€æ¬¡ï¼‰
        const currentProgress: LoopProgress = {
          ...progress,
          completedCount,
          failedCount
        };

        await this.nodeInstanceRepository.updateLoopProgress(
          nodeInstance.id,
          currentProgress,
          completedCount
        );
      } catch (error) {
        failedCount++;
        this.logger.error('Child node execution threw exception', {
          parentNodeId: nodeInstance.nodeId,
          childNodeId: child.node_id,
          error
        });

        childResults.push({
          success: false,
          error: 'Child node execution exception',
          errorDetails: error
        });

        // æ ¹æ®é”™è¯¯å¤„ç†ç­–ç•¥å†³å®šæ˜¯å¦ç»§ç»­
        const errorHandling =
          nodeInstance.executorConfig?.errorHandling || 'continue';
        if (errorHandling === 'stop') {
          this.logger.warn(
            'Stopping serial execution due to child node exception',
            {
              parentNodeId: nodeInstance.nodeId,
              failedChildNodeId: child.node_id,
              errorHandling
            }
          );
          break;
        }
      }
    }

    const finalProgress: LoopProgress = {
      ...progress,
      completedCount,
      failedCount
    };

    // æœ€ç»ˆæ›´æ–°è¿›åº¦
    await this.nodeInstanceRepository.updateLoopProgress(
      nodeInstance.id,
      finalProgress,
      completedCount
    );

    this.logger.info('Serial execution of child nodes completed', {
      nodeId: nodeInstance.nodeId,
      totalChildren: pendingChildren.length,
      completedCount,
      failedCount,
      successRate: `${completedCount}/${pendingChildren.length}`
    });

    return {
      success: true,
      data: {
        success: true,
        data: {
          status: 'executing',
          progress: finalProgress,
          executionMode: 'serial',
          childResults,
          processedCount: pendingChildren.length
        }
      }
    };
  }

  /**
   * æ‰§è¡Œå­æµç¨‹èŠ‚ç‚¹
   *
   * 1. æŸ¥è¯¢å­å·¥ä½œæµå®ä¾‹ï¼šé¦–å…ˆä½¿ç”¨external_idæŸ¥è¯¢å·¥ä½œæµå®ä¾‹
   * 2. å®ä¾‹å­˜åœ¨çš„å¤„ç†ï¼šç›´æ¥è·å–è¯¥å®ä¾‹å¹¶è°ƒç”¨executeWorkflowInstanceæ‰§è¡Œ
   * 3. å®ä¾‹ä¸å­˜åœ¨çš„å¤„ç†ï¼šæŸ¥è¯¢å·¥ä½œæµå®šä¹‰ã€åˆ›å»ºæ–°å®ä¾‹ã€è®¾ç½®external_idã€æ‰§è¡Œå®ä¾‹
   * 4. é”™è¯¯å¤„ç†ï¼šåŒ…å«external_idæŸ¥è¯¢å¤±è´¥ã€å·¥ä½œæµå®šä¹‰ä¸å­˜åœ¨ã€å®ä¾‹åˆ›å»ºå¤±è´¥ç­‰æƒ…å†µ
   */
  async executeSubProcessNode(
    context: ExecutionContext
  ): Promise<ServiceResult<ExecutionResult>> {
    const { nodeInstance, workflowInstance, nodeDefinition } = context;
    const startTime = Date.now();

    try {
      this.logger.info('Executing subprocess node', {
        nodeId: nodeInstance.nodeId,
        workflowInstanceId: nodeInstance.workflowInstanceId
      });

      // æ›´æ–°èŠ‚ç‚¹çŠ¶æ€ä¸ºæ‰§è¡Œä¸­
      await this.updateNodeStatus(nodeInstance.id, 'running');

      // 1. è·å–å­æµç¨‹èŠ‚ç‚¹å®šä¹‰
      const subprocessDef = nodeDefinition as SubprocessNodeDefinition;
      if (!subprocessDef) {
        throw new Error('Invalid subprocess node definition');
      }

      // éªŒè¯å¿…éœ€çš„é…ç½®
      if (!subprocessDef.workflowName) {
        throw new Error('subWorkflowName is required for subprocess node');
      }

      this.logger.info('Starting subprocess execution', {
        nodeId: nodeInstance.nodeId,
        subWorkflowName: subprocessDef.workflowName,
        subWorkflowVersion: subprocessDef.version
      });

      // 2. é¦–å…ˆé€šè¿‡external_idæŸ¥è¯¢å­å·¥ä½œæµå®ä¾‹
      const existingInstanceResult =
        await this.findWorkflowInstanceByExternalId(nodeInstance.id.toString());

      if (!existingInstanceResult.success) {
        throw new Error(
          `Failed to query existing subprocess instance: ${existingInstanceResult.error}`
        );
      }

      let subWorkflowInstance: WorkflowInstance;
      let workflowDefinition: WorkflowDefinitionTable;

      if (existingInstanceResult.data) {
        // 3. å®ä¾‹å­˜åœ¨çš„å¤„ç†ï¼šç›´æ¥è·å–è¯¥å®ä¾‹
        subWorkflowInstance = existingInstanceResult.data;
        this.logger.info('Found existing subprocess instance', {
          nodeId: nodeInstance.nodeId,
          subWorkflowInstanceId: subWorkflowInstance.id,
          externalId: subWorkflowInstance.externalId
        });

        // è·å–å·¥ä½œæµå®šä¹‰
        const definitionResult = await this.workflowDefinitionService.getById(
          subWorkflowInstance.workflowDefinitionId
        );
        if (!definitionResult.success) {
          throw new Error(
            `Failed to get workflow definition: ${definitionResult.error}`
          );
        }
        workflowDefinition = definitionResult.data!;
      } else {
        // 4. å®ä¾‹ä¸å­˜åœ¨çš„å¤„ç†ï¼šæŸ¥è¯¢å·¥ä½œæµå®šä¹‰å¹¶åˆ›å»ºæ–°å®ä¾‹
        this.logger.info(
          'No existing subprocess instance found, creating new one',
          {
            nodeId: nodeInstance.nodeId,
            subWorkflowName: subprocessDef.workflowName,
            subWorkflowVersion: subprocessDef.version
          }
        );

        // 4.1 æŸ¥è¯¢å·¥ä½œæµå®šä¹‰
        const definitionResult = await this.getWorkflowDefinition(
          subprocessDef.workflowName,
          subprocessDef.version
        );

        if (!definitionResult.success) {
          throw new Error(
            `Workflow definition not found: ${subprocessDef.workflowName}${subprocessDef.version ? `@${subprocessDef.workflowName}` : ''} - ${definitionResult.error}`
          );
        }
        workflowDefinition = definitionResult.data!;

        // 4.2 å¤„ç†è¾“å…¥æ˜ å°„
        const mappedInputData = this.mapSubprocessInputSimple(
          subprocessDef,
          context
        );

        // 4.3 åˆ›å»ºæ–°çš„å­å·¥ä½œæµå®ä¾‹
        const instanceResult = await this.createSubWorkflowInstance(
          workflowDefinition,
          mappedInputData,
          {
            externalId: nodeInstance.id.toString(), // è®¾ç½®external_idä¸ºå½“å‰èŠ‚ç‚¹ID
            parentWorkflowInstanceId: workflowInstance.id,
            parentNodeId: nodeInstance.nodeId,
            createdBy: 'subprocess-node',
            ...nodeInstance.inputData
          }
        );

        if (!instanceResult.success) {
          throw new Error(
            `Failed to create subprocess instance: ${instanceResult.error}`
          );
        }
        subWorkflowInstance = instanceResult.data!;

        this.logger.info('Created new subprocess instance', {
          nodeId: nodeInstance.nodeId,
          subWorkflowInstanceId: subWorkflowInstance.id,
          subWorkflowName: subprocessDef.workflowName,
          externalId: subWorkflowInstance.externalId
        });
      }

      // 5. æ‰§è¡Œå­å·¥ä½œæµå®ä¾‹
      this.logger.info('Executing subprocess workflow instance', {
        nodeId: nodeInstance.nodeId,
        subWorkflowInstanceId: subWorkflowInstance.id
      });

      const executionResult = await this.executeWorkflowInstance(
        workflowDefinition,
        subWorkflowInstance
      );

      if (!executionResult.success) {
        throw new Error(
          `Sub-workflow execution failed: ${executionResult.error}`
        );
      }

      // 6. å¤„ç†è¾“å‡ºæ˜ å°„
      const mappedOutput = this.mapSubprocessOutputSimple(
        subprocessDef,
        subWorkflowInstance.outputData
      );

      const duration = Date.now() - startTime;

      // 7. æ›´æ–°èŠ‚ç‚¹çŠ¶æ€ä¸ºå®Œæˆ
      await this.updateNodeStatus(nodeInstance.id, 'completed');
      await this.nodeInstanceRepository.updateNodeInstance(nodeInstance.id, {
        output_data: mappedOutput,
        completed_at: new Date(),
        duration_ms: duration
      });

      this.logger.info('Subprocess node execution completed', {
        nodeId: nodeInstance.nodeId,
        subWorkflowInstanceId: subWorkflowInstance.id,
        duration
      });

      return {
        success: true,
        data: {
          success: true,
          data: mappedOutput,
          duration
        }
      };
    } catch (error) {
      this.logger.error('Failed to execute subprocess node', {
        error,
        nodeId: nodeInstance.nodeId,
        workflowInstanceId: nodeInstance.workflowInstanceId
      });

      await this.updateNodeStatus(
        nodeInstance.id,
        'failed',
        'Subprocess execution error',
        error
      );

      return {
        success: false,
        error: 'Failed to execute subprocess node',
        errorDetails: error
      };
    }
  }

  /**
   * é€šè¿‡external_idæŸ¥è¯¢å·¥ä½œæµå®ä¾‹
   */
  private async findWorkflowInstanceByExternalId(
    externalId: string
  ): Promise<ServiceResult<WorkflowInstance | null>> {
    try {
      this.logger.debug('Querying workflow instance by external_id', {
        externalId
      });

      // ä½¿ç”¨WorkflowInstanceServiceçš„findByExternalIdæ–¹æ³•
      const result =
        await this.workflowInstanceService.findByExternalId(externalId);

      if (!result.success) {
        this.logger.warn('Failed to query workflow instance by external_id', {
          externalId,
          error: result.error
        });
        return {
          success: false,
          error: result.error,
          errorDetails: result.errorDetails
        };
      }

      this.logger.debug('Workflow instance query completed', {
        externalId,
        found: !!result.data,
        instanceId: result.data?.id
      });

      return {
        success: true,
        data: result.data
      };
    } catch (error) {
      this.logger.error('Error querying workflow instance by external_id', {
        externalId,
        error
      });
      return {
        success: false,
        error: 'Failed to query workflow instance by external_id',
        errorDetails: error
      };
    }
  }

  /**
   * è·å–å·¥ä½œæµå®šä¹‰
   */
  private async getWorkflowDefinition(
    workflowName: string,
    workflowVersion?: string
  ): Promise<ServiceResult<WorkflowDefinitionTable>> {
    try {
      this.logger.debug('Getting workflow definition', {
        workflowName,
        workflowVersion
      });

      const result = workflowVersion
        ? await this.workflowDefinitionService.getByNameAndVersion(
            workflowName,
            workflowVersion
          )
        : await this.workflowDefinitionService.getActiveByName(workflowName);

      if (!result.success) {
        this.logger.warn('Failed to get workflow definition', {
          workflowName,
          workflowVersion,
          error: result.error
        });
        return {
          success: false,
          error: result.error,
          errorDetails: result.errorDetails
        };
      }

      this.logger.debug('Workflow definition found', {
        workflowName,
        workflowVersion,
        definitionId: result.data!.id
      });

      return {
        success: true,
        data: result.data!
      };
    } catch (error) {
      this.logger.error('Error getting workflow definition', {
        workflowName,
        workflowVersion,
        error
      });
      return {
        success: false,
        error: 'Failed to get workflow definition',
        errorDetails: error
      };
    }
  }

  /**
   * åˆ›å»ºå­å·¥ä½œæµå®ä¾‹
   */
  private async createSubWorkflowInstance(
    workflowDefinition: WorkflowDefinitionTable,
    inputData: Record<string, any> = {},
    contextData: Record<string, any> = {}
  ): Promise<ServiceResult<WorkflowInstance>> {
    try {
      this.logger.debug('Creating subprocess workflow instance', {
        workflowDefinitionId: workflowDefinition.id
      });

      const result = await this.workflowInstanceService.getWorkflowInstance(
        workflowDefinition,
        {
          inputData,
          contextData
        }
      );

      if (!result.success) {
        this.logger.warn('Failed to create subprocess workflow instance', {
          workflowDefinitionId: workflowDefinition.id,
          error: result.error
        });
        return {
          success: false,
          error: result.error,
          errorDetails: result.errorDetails
        };
      }

      this.logger.debug('Subprocess workflow instance created', {
        workflowDefinitionId: workflowDefinition.id,
        instanceId: result.data!.id
      });

      return {
        success: true,
        data: result.data!
      };
    } catch (error) {
      this.logger.error('Error creating subprocess workflow instance', {
        workflowDefinitionId: workflowDefinition.id,
        error
      });
      return {
        success: false,
        error: 'Failed to create subprocess workflow instance',
        errorDetails: error
      };
    }
  }

  async executeWorkflowInstance(
    workflowDefinition: WorkflowDefinitionTable,
    workflowInstance: WorkflowInstance
  ): Promise<ServiceResult<any>> {
    // TODO: å®ç°å·¥ä½œæµå®ä¾‹æ‰§è¡Œé€»è¾‘
    // 2. æ›´æ–°å·¥ä½œæµçŠ¶æ€ä¸ºæ‰§è¡Œä¸­
    await this.workflowInstanceService.updateStatus(
      workflowInstance.id,
      'running'
    );

    // 3. è·å–å·¥ä½œæµçš„æ‰€æœ‰èŠ‚ç‚¹å®šä¹‰ï¼ˆæŒ‰æ‰§è¡Œé¡ºåºï¼Œæ”¯æŒæ£€æŸ¥ç‚¹æ¢å¤ï¼‰
    const orderedNodes = await this.getOrderedNodes(
      workflowDefinition.definition,
      workflowInstance
    );

    if (orderedNodes.length === 0) {
      // æ²¡æœ‰èŠ‚ç‚¹ï¼Œå·¥ä½œæµå®Œæˆ
      await this.completeWorkflow(workflowInstance);
      // è·å–æœ€åä¸€ä¸ªèŠ‚ç‚¹çš„è¾“å‡ºä½œä¸ºå·¥ä½œæµçš„è¾“å‡º
      return { success: true };
    }
    // 4. æ„å»ºæ‰§è¡Œä¸Šä¸‹æ–‡
    const executionContext = {
      workflowInstance
    } as ExecutionContext;
    // 5. Forå¾ªç¯é¡ºåºæ‰§è¡Œæ¯ä¸ªèŠ‚ç‚¹
    for (const nodeDefinition of orderedNodes) {
      this.logger.info('Processing node', {
        nodeId: nodeDefinition.nodeId,
        nodeType: nodeDefinition.nodeType,
        instanceId: workflowInstance.id
      });
      // 5.1 è·å–æˆ–åˆ›å»ºèŠ‚ç‚¹å®ä¾‹
      const nodeInstanceResult = await this.getOrCreateNodeInstance(
        workflowInstance.id,
        nodeDefinition
      );

      if (!nodeInstanceResult.success) {
        await this.handleWorkflowError(
          workflowInstance,
          `Failed to get or create node instance: ${nodeDefinition.nodeId}`,
          nodeInstanceResult.error
        );
        return { success: false, error: nodeInstanceResult.error };
      }

      const nodeInstance = nodeInstanceResult.data!;

      // 5.2 æ£€æŸ¥èŠ‚ç‚¹æ‰§è¡Œæ¡ä»¶å’ŒçŠ¶æ€
      if (!this.shouldExecuteNode(nodeInstance)) {
        this.logger.info('Skipping node execution', {
          nodeId: nodeInstance.nodeId,
          status: nodeInstance.status,
          reason: 'Node already completed or should not execute'
        });
        continue;
      }

      // 5.3 å¤„ç†èŠ‚ç‚¹é‡è¯•é€»è¾‘
      const retryResult = await this.handleNodeRetryLogic(nodeInstance);
      if (!retryResult.shouldContinue) {
        if (retryResult.shouldFail) {
          await this.handleWorkflowError(
            workflowInstance,
            `Node ${nodeInstance.nodeId} failed after ${nodeInstance.maxRetries} retries`
          );
          return { success: false, error: retryResult.error };
        }
        continue; // è·³è¿‡å½“å‰èŠ‚ç‚¹ï¼Œç»§ç»­ä¸‹ä¸€ä¸ª
      }

      // 5.4.1 æ£€æŸ¥å’Œè·å–å‰ç½®èŠ‚ç‚¹ç»“æœ
      await this.loadPreviousNodeOutput(
        nodeInstance,
        executionContext,
        orderedNodes
      );

      // 5.4.2 è¿›è¡Œæ¨¡æ¿å˜é‡æ›¿æ¢ï¼ˆç»Ÿä¸€å¤„ç†input_dataï¼‰
      const resolvedConfig = await this.resolveTemplateVariables(
        executionContext,
        {},
        nodeDefinition.inputData
      );

      // è®¾ç½®æ‰§è¡Œä¸Šä¸‹æ–‡ï¼ˆä½¿ç”¨è§£æåçš„é…ç½®ï¼‰
      executionContext.config = resolvedConfig || {};
      // è®¾ç½®èŠ‚ç‚¹å®šä¹‰å’Œå®ä¾‹
      executionContext.nodeDefinition = nodeDefinition;
      // è®¾ç½®èŠ‚ç‚¹å®ä¾‹
      executionContext.nodeInstance = nodeInstance;

      // 5.5 æ ¹æ®èŠ‚ç‚¹ç±»å‹æ‰§è¡Œä¸åŒé€»è¾‘
      const executionResult = await this.executeNode(executionContext);

      // 5.6 å¤„ç†æ‰§è¡Œç»“æœ
      const handleResult = await this.handleNodeExecutionResult(
        nodeInstance,
        executionResult,
        workflowInstance,
        executionContext
      );

      if (!handleResult.success) {
        return { success: false, error: handleResult.error };
      }

      // 5.7 æ›´æ–°æ£€æŸ¥ç‚¹
      await this.workflowInstanceService.updateCurrentNode(
        workflowInstance.id,
        nodeInstance.nodeId,
        { lastCompletedNode: nodeInstance.nodeId, timestamp: new Date() }
      );
    }
    // 6. å·¥ä½œæµå®Œæˆ
    await this.completeWorkflow(workflowInstance);
    return { success: true, data: executionContext.previousNodeOutput };
  }

  /**
   * ä¿å­˜èŠ‚ç‚¹æ‰§è¡Œç»“æœ
   */
  private async saveNodeExecutionResult(
    nodeInstance: NodeInstance,
    executionResult: ServiceResult<any>,
    executionContext: ExecutionContext
  ): Promise<void> {
    try {
      if (!executionResult.success || !executionResult.data) {
        this.logger.debug('No output data to save', {
          nodeId: nodeInstance.nodeId,
          success: executionResult.success
        });
        return;
      }

      this.logger.debug('Saving node execution result', {
        nodeId: nodeInstance.nodeId,
        hasOutputData: !!executionResult.data
      });

      // 1. æ›´æ–°æ•°æ®åº“ä¸­çš„èŠ‚ç‚¹è¾“å‡ºæ•°æ®å’ŒçŠ¶æ€
      const updateResult = await this.nodeInstanceRepository.updateNodeInstance(
        nodeInstance.id,
        executionResult.data
      );

      if (!updateResult.success) {
        this.logger.error('Failed to update node output data in database', {
          nodeId: nodeInstance.nodeId,
          error: updateResult.error
        });
        // ä¸æŠ›å‡ºé”™è¯¯ï¼Œç»§ç»­æ‰§è¡Œ
      }

      // 2. æ›´æ–°æ‰§è¡Œä¸Šä¸‹æ–‡ä¸­çš„å‰ç½®èŠ‚ç‚¹è¾“å‡ºï¼ˆä¸ºä¸‹ä¸€ä¸ªèŠ‚ç‚¹å‡†å¤‡ï¼‰
      executionContext.previousNodeOutput = executionResult.data;

      // 3. æ›´æ–°èŠ‚ç‚¹å®ä¾‹çš„è¾“å‡ºæ•°æ®ï¼ˆå†…å­˜ä¸­ï¼‰
      nodeInstance.outputData = executionResult.data;
      nodeInstance.status = 'completed';
      nodeInstance.completedAt = new Date();

      this.logger.debug('Node execution result saved successfully', {
        nodeId: nodeInstance.nodeId,
        outputDataKeys: Object.keys(executionResult.data || {})
      });
    } catch (error) {
      this.logger.error('Failed to save node execution result', {
        error,
        nodeId: nodeInstance.nodeId
      });
      // ä¸æŠ›å‡ºé”™è¯¯ï¼Œç¡®ä¿å·¥ä½œæµèƒ½ç»§ç»­æ‰§è¡Œ
    }
  }

  /**
   * å¤„ç†èŠ‚ç‚¹æ‰§è¡Œç»“æœ
   */
  private async handleNodeExecutionResult(
    nodeInstance: NodeInstance,
    executionResult: ServiceResult<any>,
    workflowInstance: WorkflowInstance,
    executionContext: ExecutionContext
  ): Promise<ServiceResult<void>> {
    try {
      if (!executionResult.success) {
        // èŠ‚ç‚¹æ‰§è¡Œå¤±è´¥
        if (nodeInstance.retryCount < nodeInstance.maxRetries) {
          // å¯ä»¥é‡è¯•ï¼Œæ›´æ–°é‡è¯•è®¡æ•°
          nodeInstance.retryCount++;
          await this.updateNodeStatus(
            nodeInstance.id,
            'failed_retry',
            executionResult.error,
            executionResult.errorDetails
          );

          // ç­‰å¾…ä¸€æ®µæ—¶é—´åé‡è¯•
          await sleep(10000); // 5ç§’å»¶è¿Ÿ
          return { success: true }; // ç»§ç»­æ‰§è¡Œ
        } else {
          // é‡è¯•æ¬¡æ•°å·²è¾¾ä¸Šé™
          await this.handleWorkflowError(
            workflowInstance,
            `Node ${nodeInstance.nodeId} execution failed`,
            executionResult.errorDetails
          );
          return {
            success: false,
            error: `Node ${nodeInstance.nodeId} execution failed after retries`
          };
        }
      }

      // èŠ‚ç‚¹æ‰§è¡ŒæˆåŠŸ - ä¿å­˜æ‰§è¡Œç»“æœ
      await this.saveNodeExecutionResult(
        nodeInstance,
        executionResult,
        executionContext
      );

      this.logger.info('Node executed successfully', {
        nodeId: nodeInstance.nodeId,
        workflowInstanceId: workflowInstance.id,
        hasOutputData: !!executionResult.data
      });

      return { success: true };
    } catch (error) {
      this.logger.error('Failed to handle node execution result', {
        error,
        nodeId: nodeInstance.nodeId
      });

      return {
        success: false,
        error: 'Failed to handle node execution result',
        errorDetails: error
      };
    }
  }

  /**
   * æ£€æŸ¥å’ŒåŠ è½½å‰ç½®èŠ‚ç‚¹è¾“å‡ºæ•°æ®
   * ä¼˜åŒ–ç‰ˆæœ¬ï¼šåªæŸ¥è¯¢ç›´æ¥å‰ç½®èŠ‚ç‚¹ï¼Œå‡å°‘æ•°æ®åº“æŸ¥è¯¢
   */
  private async loadPreviousNodeOutput(
    nodeInstance: NodeInstance,
    executionContext: ExecutionContext,
    orderedNodes: any[]
  ): Promise<void> {
    try {
      if (!nodeInstance) {
        return;
      }

      const currentNodeId = nodeInstance.nodeId;
      const workflowInstanceId = executionContext.workflowInstance.id;

      this.logger.debug('Loading previous node output', {
        currentNodeId,
        workflowInstanceId
      });

      // æ¡ä»¶æ£€æŸ¥ä¼˜åŒ–ï¼šåªæœ‰å½“å‰ç½®èŠ‚ç‚¹è¾“å‡ºä¸å­˜åœ¨æ—¶æ‰æŸ¥è¯¢
      if (
        executionContext.previousNodeOutput !== undefined &&
        executionContext.previousNodeOutput !== null
      ) {
        this.logger.debug(
          'Previous node output already exists in context, skipping database query'
        );
        return;
      }

      // æŸ¥æ‰¾å½“å‰èŠ‚ç‚¹åœ¨æœ‰åºåˆ—è¡¨ä¸­çš„ä½ç½®
      const currentNodeIndex = orderedNodes.findIndex(
        (node) => (node.nodeId || node.id) === currentNodeId
      );

      if (currentNodeIndex <= 0) {
        // ç¬¬ä¸€ä¸ªèŠ‚ç‚¹æˆ–æœªæ‰¾åˆ°ï¼Œæ²¡æœ‰å‰ç½®èŠ‚ç‚¹
        this.logger.debug('No previous node for current node', {
          currentNodeId
        });
        return;
      }

      // æŸ¥è¯¢èŒƒå›´é™åˆ¶ï¼šåªæŸ¥è¯¢ç›´æ¥å‰ç½®èŠ‚ç‚¹ï¼ˆå½“å‰èŠ‚ç‚¹çš„ä¸Šä¸€ä¸ªèŠ‚ç‚¹ï¼‰
      const directPreviousNodeDef = orderedNodes[currentNodeIndex - 1];
      const directPreviousNodeId =
        directPreviousNodeDef.nodeId || directPreviousNodeDef.id;

      this.logger.debug('Checking direct previous node', {
        currentNodeId,
        directPreviousNodeId,
        currentNodeIndex
      });

      const nodeInstanceResult = await this.getNodeInstance(
        workflowInstanceId,
        directPreviousNodeId
      );

      if (nodeInstanceResult.success && nodeInstanceResult.data) {
        const previousUnifiedNodeInstance = nodeInstanceResult.data;

        if (
          previousUnifiedNodeInstance.status === 'completed' &&
          previousUnifiedNodeInstance.outputData
        ) {
          // æ‰¾åˆ°ç›´æ¥å‰ç½®èŠ‚ç‚¹çš„è¾“å‡ºæ•°æ®
          executionContext.previousNodeOutput =
            previousUnifiedNodeInstance.outputData;

          this.logger.debug('Loaded direct previous node output', {
            currentNodeId,
            directPreviousNodeId,
            hasOutputData: !!previousUnifiedNodeInstance.outputData,
            outputDataKeys: Object.keys(
              previousUnifiedNodeInstance.outputData || {}
            )
          });
        } else {
          this.logger.debug(
            'Direct previous node not completed or has no output',
            {
              currentNodeId,
              directPreviousNodeId,
              status: previousUnifiedNodeInstance.status,
              hasOutputData: !!previousUnifiedNodeInstance.outputData
            }
          );
        }
      } else {
        this.logger.debug('Direct previous node instance not found', {
          currentNodeId,
          directPreviousNodeId
        });
      }
    } catch (error) {
      this.logger.warn('Failed to load previous node output', {
        error,
        currentNodeId: nodeInstance?.nodeId,
        workflowInstanceId: executionContext.workflowInstance.id
      });
      // ä¸æŠ›å‡ºé”™è¯¯ï¼Œç»§ç»­æ‰§è¡Œ
    }
  }

  /**
   * å¤„ç†èŠ‚ç‚¹é‡è¯•é€»è¾‘
   */
  private async handleNodeRetryLogic(nodeInstance: NodeInstance): Promise<{
    shouldContinue: boolean;
    shouldFail: boolean;
    error?: string;
  }> {
    if (nodeInstance.status === 'failed') {
      // èŠ‚ç‚¹å¤±è´¥ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦é‡è¯•
      if (nodeInstance.retryCount < nodeInstance.maxRetries) {
        this.logger.info('Retrying failed node', {
          nodeId: nodeInstance.nodeId,
          retryCount: nodeInstance.retryCount + 1,
          maxRetries: nodeInstance.maxRetries
        });

        // é‡ç½®èŠ‚ç‚¹çŠ¶æ€ä¸ºå¾…é‡è¯•
        await this.updateNodeStatus(nodeInstance.id, 'failed_retry');

        // ç­‰å¾…é‡è¯•å»¶è¿Ÿ
        if (nodeInstance.retryDelaySeconds) {
          await sleep(nodeInstance.retryDelaySeconds * 1000);
        }

        return { shouldContinue: true, shouldFail: false };
      } else {
        // é‡è¯•æ¬¡æ•°å·²è¾¾ä¸Šé™
        return {
          shouldContinue: false,
          shouldFail: true,
          error: `Node failed after ${nodeInstance.maxRetries} retries`
        };
      }
    }

    return { shouldContinue: true, shouldFail: false };
  }

  /**
   * æ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦åº”è¯¥æ‰§è¡Œ
   */
  private shouldExecuteNode(nodeInstance: NodeInstance): boolean {
    // å¦‚æœèŠ‚ç‚¹å·²å®Œæˆï¼Œè·³è¿‡æ‰§è¡Œ
    if (nodeInstance.status === 'completed') {
      return false;
    }

    // å¦‚æœèŠ‚ç‚¹æ­£åœ¨è¿è¡Œï¼Œè·³è¿‡æ‰§è¡Œï¼ˆé¿å…é‡å¤æ‰§è¡Œï¼‰
    if (nodeInstance.status === 'running') {
      return false;
    }

    // æ£€æŸ¥æ¡ä»¶è¡¨è¾¾å¼ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
    if (nodeInstance.condition) {
      // TODO: å®ç°æ¡ä»¶è¡¨è¾¾å¼è¯„ä¼°
      // æš‚æ—¶è¿”å›trueï¼Œåç»­å¯ä»¥é›†æˆè¡¨è¾¾å¼å¼•æ“
      return true;
    }

    return true;
  }

  /**
   * å¤„ç†å·¥ä½œæµé”™è¯¯
   */
  public async handleWorkflowError(
    instance: WorkflowInstance,
    error: string,
    errorDetails?: any
  ): Promise<void> {
    await this.workflowInstanceService.updateStatus(
      instance.id,
      'failed',
      error,
      errorDetails
    );
    this.logger.error('Workflow failed', {
      instanceId: instance.id,
      error,
      errorDetails
    });
  }

  /**
   * è·å–æˆ–åˆ›å»ºèŠ‚ç‚¹å®ä¾‹
   */
  private async getOrCreateNodeInstance(
    workflowInstanceId: number,
    nodeDefinition: NodeDefinition
  ): Promise<ServiceResult<NodeInstance>> {
    try {
      const nodeId = nodeDefinition.nodeId;

      this.logger.debug('Getting or creating node instance', {
        workflowInstanceId,
        nodeId,
        nodeType: nodeDefinition.nodeType
      });

      // 1. å°è¯•è·å–å·²å­˜åœ¨çš„èŠ‚ç‚¹å®ä¾‹
      const existingInstanceResult = await this.getNodeInstance(
        workflowInstanceId,
        nodeId
      );

      if (existingInstanceResult.success && existingInstanceResult.data) {
        this.logger.debug('Found existing node instance', {
          nodeId,
          instanceId: existingInstanceResult.data.id,
          status: existingInstanceResult.data.status
        });
        return existingInstanceResult;
      }

      // 2. åˆ›å»ºæ–°çš„èŠ‚ç‚¹å®ä¾‹
      this.logger.debug('Creating new node instance', { nodeId });

      const newInstanceData = {
        workflowInstanceId,
        nodeId,
        nodeName: nodeDefinition.nodeName || nodeId,
        nodeDescription: nodeDefinition.nodeDescription,
        nodeType: nodeDefinition.nodeType,
        executor: (nodeDefinition as any).executor,
        inputData: nodeDefinition.inputData,
        timeoutSeconds: nodeDefinition.timeoutSeconds,
        maxRetries: nodeDefinition.maxRetries || 3,
        retryDelaySeconds: nodeDefinition.retryDelaySeconds,
        condition: nodeDefinition.condition,
        status: 'pending' as const,
        retryCount: 0,
        loopCompletedCount: 0
      };

      const createResult = await this.createNodeInstance(newInstanceData);

      if (createResult.success) {
        this.logger.debug('Created new node instance', {
          nodeId,
          instanceId: createResult.data!.id
        });
      }

      return createResult;
    } catch (error) {
      this.logger.error('Failed to get or create node instance', {
        error,
        workflowInstanceId,
        nodeId: nodeDefinition.nodeId
      });

      return {
        success: false,
        error: 'Failed to get or create node instance',
        errorDetails: error
      };
    }
  }

  /**
   * å®Œæˆå·¥ä½œæµ
   */
  private async completeWorkflow(instance: WorkflowInstance): Promise<void> {
    await this.workflowInstanceService.updateStatus(instance.id, 'completed');
    this.logger.info('Workflow completed successfully', {
      instanceId: instance.id
    });
  }

  /**
   * è·å–å·¥ä½œæµçš„æ‰€æœ‰èŠ‚ç‚¹å®šä¹‰ï¼ˆæŒ‰æ‰§è¡Œé¡ºåºï¼‰
   * æ”¯æŒä»æ£€æŸ¥ç‚¹æ¢å¤æ‰§è¡Œ
   */
  private async getOrderedNodes(
    workflowDefinition: WorkflowDefinitionData,
    workflowInstance?: WorkflowInstance
  ): Promise<NodeDefinition[]> {
    const nodes = workflowDefinition.nodes || [];
    const connections = workflowDefinition.connections || [];

    this.logger.debug('Getting ordered nodes', {
      totalNodes: nodes.length,
      totalConnections: connections.length,
      hasCheckpoint: !!workflowInstance?.currentNodeId
    });

    // 1. è·å–åŸºç¡€æœ‰åºèŠ‚ç‚¹åˆ—è¡¨
    let orderedNodes: any[] = [];

    if (connections.length > 0) {
      // åŸºäºè¿æ¥å…³ç³»æ’åº
      orderedNodes = this.topologicalSort(nodes, connections);
    } else if (nodes.some((node: any) => node.dependsOn?.length > 0)) {
      // åŸºäºä¾èµ–å…³ç³»æ’åº
      orderedNodes = this.sortByDependencies(nodes);
    } else {
      // é»˜è®¤æŒ‰å®šä¹‰é¡ºåºæ‰§è¡Œ
      orderedNodes = nodes;
    }

    // 2. å¦‚æœæ²¡æœ‰å·¥ä½œæµå®ä¾‹æˆ–æ£€æŸ¥ç‚¹ï¼Œè¿”å›æ‰€æœ‰èŠ‚ç‚¹
    if (!workflowInstance || !workflowInstance.currentNodeId) {
      this.logger.debug('No checkpoint found, returning all nodes', {
        nodeCount: orderedNodes.length
      });
      return orderedNodes;
    }

    // 3. ä»æ£€æŸ¥ç‚¹æ¢å¤ï¼šè¿‡æ»¤å‡ºå¾…æ‰§è¡Œçš„èŠ‚ç‚¹
    return await this.filterNodesFromCheckpoint(orderedNodes, workflowInstance);
  }

  /**
   * ä»æ£€æŸ¥ç‚¹è¿‡æ»¤å¾…æ‰§è¡Œçš„èŠ‚ç‚¹
   */
  private async filterNodesFromCheckpoint(
    orderedNodes: any[],
    workflowInstance: WorkflowInstance
  ): Promise<any[]> {
    try {
      const currentNodeId = workflowInstance.currentNodeId;

      this.logger.debug('Filtering nodes from checkpoint', {
        currentNodeId,
        totalNodes: orderedNodes.length,
        workflowInstanceId: workflowInstance.id
      });

      // 1. æ‰¾åˆ°æ£€æŸ¥ç‚¹èŠ‚ç‚¹åœ¨æœ‰åºåˆ—è¡¨ä¸­çš„ä½ç½®
      const checkpointIndex = orderedNodes.findIndex(
        (node) => (node.nodeId || node.id) === currentNodeId
      );

      if (checkpointIndex === -1) {
        this.logger.warn(
          'Checkpoint node not found in ordered nodes, starting from beginning',
          {
            currentNodeId,
            availableNodes: orderedNodes.map((n) => n.nodeId || n.id)
          }
        );
        // æ£€æŸ¥ç‚¹èŠ‚ç‚¹ä¸å­˜åœ¨ï¼Œä»ç¬¬ä¸€ä¸ªèŠ‚ç‚¹å¼€å§‹
        return orderedNodes;
      }

      // 2. è·å–ä»æ£€æŸ¥ç‚¹å¼€å§‹çš„æ‰€æœ‰èŠ‚ç‚¹
      const candidateNodes = orderedNodes.slice(checkpointIndex);

      // 3. æŸ¥è¯¢å„èŠ‚ç‚¹çš„å®é™…æ‰§è¡ŒçŠ¶æ€
      const filteredNodes: any[] = [];

      for (const node of candidateNodes) {
        const nodeId = node.nodeId || node.id;

        // æŸ¥è¯¢èŠ‚ç‚¹å®ä¾‹çŠ¶æ€
        const nodeInstanceResult = await this.getNodeInstance(
          workflowInstance.id,
          nodeId
        );

        if (!nodeInstanceResult.success || !nodeInstanceResult.data) {
          // èŠ‚ç‚¹å®ä¾‹ä¸å­˜åœ¨ï¼Œè¯´æ˜æœªæ‰§è¡Œè¿‡ï¼Œéœ€è¦æ‰§è¡Œ
          filteredNodes.push(node);
          this.logger.debug('Node instance not found, will execute', {
            nodeId
          });
        } else {
          const nodeInstance = nodeInstanceResult.data;
          const status = nodeInstance.status;

          // åªåŒ…å«å¾…æ‰§è¡Œçš„èŠ‚ç‚¹ï¼ˆpendingã€failedã€failed_retryï¼‰
          if (['pending', 'failed', 'failed_retry'].includes(status)) {
            filteredNodes.push(node);
            this.logger.debug('Node needs execution', { nodeId, status });
          } else if (status === 'completed') {
            this.logger.debug('Node already completed, skipping', {
              nodeId,
              status
            });
          } else {
            // å…¶ä»–çŠ¶æ€ï¼ˆå¦‚runningï¼‰ä¹ŸåŒ…å«è¿›æ¥ï¼Œè®©æ‰§è¡Œå¼•æ“å¤„ç†
            filteredNodes.push(node);
            this.logger.debug(
              'Node in uncertain state, including for execution',
              { nodeId, status }
            );
          }
        }
      }

      this.logger.info('Filtered nodes from checkpoint', {
        checkpointNodeId: currentNodeId,
        checkpointIndex,
        totalCandidates: candidateNodes.length,
        filteredCount: filteredNodes.length,
        filteredNodeIds: filteredNodes.map((n) => n.nodeId || n.id)
      });

      return filteredNodes;
    } catch (error) {
      this.logger.error('Failed to filter nodes from checkpoint', {
        error,
        workflowInstanceId: workflowInstance.id,
        currentNodeId: workflowInstance.currentNodeId
      });

      // å‡ºé”™æ—¶è¿”å›æ‰€æœ‰èŠ‚ç‚¹ï¼Œç¡®ä¿å·¥ä½œæµèƒ½ç»§ç»­æ‰§è¡Œ
      return orderedNodes;
    }
  }

  /**
   * æ‹“æ‰‘æ’åºï¼ˆåŸºäºè¿æ¥å…³ç³»ï¼‰
   */
  private topologicalSort(nodes: any[], connections: any[]): any[] {
    const nodeMap = new Map(
      nodes.map((node) => [node.nodeId || node.id, node])
    );
    const inDegree = new Map<string, number>();
    const adjList = new Map<string, string[]>();

    // åˆå§‹åŒ–
    nodes.forEach((node) => {
      const nodeId = node.nodeId || node.id;
      inDegree.set(nodeId, 0);
      adjList.set(nodeId, []);
    });

    // æ„å»ºé‚»æ¥è¡¨å’Œå…¥åº¦
    connections.forEach((conn) => {
      const from = conn.source;
      const to = conn.target;

      if (adjList.has(from) && inDegree.has(to)) {
        adjList.get(from)!.push(to);
        inDegree.set(to, inDegree.get(to)! + 1);
      }
    });

    // æ‹“æ‰‘æ’åº
    const queue: string[] = [];
    const result: any[] = [];

    // æ‰¾åˆ°æ‰€æœ‰å…¥åº¦ä¸º0çš„èŠ‚ç‚¹
    inDegree.forEach((degree, nodeId) => {
      if (degree === 0) {
        queue.push(nodeId);
      }
    });

    while (queue.length > 0) {
      const currentId = queue.shift()!;
      const currentNode = nodeMap.get(currentId);

      if (currentNode) {
        result.push(currentNode);

        // å¤„ç†é‚»æ¥èŠ‚ç‚¹
        adjList.get(currentId)?.forEach((neighborId) => {
          const newDegree = inDegree.get(neighborId)! - 1;
          inDegree.set(neighborId, newDegree);

          if (newDegree === 0) {
            queue.push(neighborId);
          }
        });
      }
    }

    return result;
  }

  /**
   * æŒ‰ä¾èµ–å…³ç³»æ’åº
   */
  private sortByDependencies(nodes: any[]): any[] {
    const nodeMap = new Map(
      nodes.map((node) => [node.nodeId || node.id, node])
    );
    const visited = new Set<string>();
    const result: any[] = [];

    const visit = (nodeId: string) => {
      if (visited.has(nodeId)) return;

      const node = nodeMap.get(nodeId);
      if (!node) return;

      // å…ˆè®¿é—®ä¾èµ–èŠ‚ç‚¹
      const dependencies = node.dependsOn || [];
      dependencies.forEach((depId: string) => visit(depId));

      visited.add(nodeId);
      result.push(node);
    };

    // è®¿é—®æ‰€æœ‰èŠ‚ç‚¹
    nodes.forEach((node) => {
      const nodeId = node.nodeId || node.id;
      visit(nodeId);
    });

    return result;
  }

  /**
   * æ‰§è¡Œå¹¶è¡ŒèŠ‚ç‚¹
   *
   * 1. ä»å®šä¹‰ä¸­è·å–æ‰€æœ‰å­èŠ‚ç‚¹å®šä¹‰
   * 2. è·å–æ‰€æœ‰æœªæ‰§è¡Œçš„å­èŠ‚ç‚¹å®ä¾‹
   * 3. å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰å­èŠ‚ç‚¹ executeNode(childNode, context)
   * 4. æ‰€æœ‰å­èŠ‚ç‚¹å®Œæˆåæ›´æ–°èŠ‚ç‚¹çŠ¶æ€
   */
  async executeParallelNode(
    node: NodeInstance,
    context: ExecutionContext
  ): Promise<ServiceResult<ExecutionResult>> {
    try {
      this.logger.info('Executing parallel node', {
        nodeId: node.nodeId,
        workflowInstanceId: node.workflowInstanceId
      });

      // æ›´æ–°èŠ‚ç‚¹çŠ¶æ€ä¸ºæ‰§è¡Œä¸­
      await this.updateNodeStatus(node.id, 'running');

      // è·å–æ‰€æœ‰å­èŠ‚ç‚¹å®ä¾‹
      const childrenResult = await this.nodeInstanceRepository.findChildNodes(
        node.id
      );
      if (!childrenResult.success) {
        return {
          success: false,
          error: 'Failed to get child nodes',
          errorDetails: childrenResult.error
        };
      }

      const children = childrenResult.data || [];

      if (children.length === 0) {
        // æ²¡æœ‰å­èŠ‚ç‚¹ï¼Œç›´æ¥å®Œæˆ
        await this.updateNodeStatus(node.id, 'completed');
        return {
          success: true,
          data: {
            success: true,
            data: { status: 'completed', childCount: 0 }
          }
        };
      }

      // å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰å­èŠ‚ç‚¹
      const childResults = await Promise.allSettled(
        children.map((child) => {
          const childContext: ExecutionContext = {
            ...context,
            nodeInstance: this.mapToBusinessModel(child)
          };
          return this.executeNode(childContext);
        })
      );

      let successCount = 0;
      let failedCount = 0;

      childResults.forEach((result) => {
        if (result.status === 'fulfilled' && result.value.success) {
          successCount++;
        } else {
          failedCount++;
        }
      });

      // æ›´æ–°èŠ‚ç‚¹çŠ¶æ€
      if (failedCount === 0) {
        await this.updateNodeStatus(node.id, 'completed');
      } else {
        await this.updateNodeStatus(
          node.id,
          'failed',
          `${failedCount} child nodes failed`
        );
      }

      return {
        success: failedCount === 0,
        data: {
          success: failedCount === 0,
          data: {
            status: failedCount === 0 ? 'completed' : 'failed',
            successCount,
            failedCount,
            totalCount: children.length
          }
        }
      };
    } catch (error) {
      this.logger.error('Failed to execute parallel node', { error, node });
      await this.updateNodeStatus(
        node.id,
        'failed',
        'Parallel execution error',
        error
      );

      return {
        success: false,
        error: 'Failed to execute parallel node',
        errorDetails: error
      };
    }
  }

  /**
   * é€šç”¨èŠ‚ç‚¹æ‰§è¡Œå…¥å£
   *
   * 1. æ ¹æ®èŠ‚ç‚¹ç±»å‹åˆ¤æ–­æ‰§è¡Œç­–ç•¥
   * 2. ç®€å•ç±»å‹ï¼šè°ƒç”¨ executeSimpleNode
   * 3. å¾ªç¯èŠ‚ç‚¹ç±»å‹ï¼šè°ƒç”¨ executeLoopNode
   * 4. å­æµç¨‹èŠ‚ç‚¹ç±»å‹ï¼šè°ƒç”¨ executeSubProcessNode
   * 5. å¹¶è¡ŒèŠ‚ç‚¹ç±»å‹ï¼šè°ƒç”¨ executeParallelNode
   */
  async executeNode(
    executionContext: ExecutionContext
  ): Promise<ServiceResult<ExecutionResult>> {
    try {
      this.logger.info('Executing node', {
        nodeName: executionContext.nodeInstance.nodeName,
        nodeType: executionContext.nodeInstance.nodeType,
        workflowInstanceId: executionContext.workflowInstance.id
      });

      switch (executionContext.nodeInstance.nodeType) {
        case 'simple':
          return await this.executeSimpleNode(executionContext);
        case 'loop':
          return await this.executeLoopNode(executionContext);
        case 'subprocess':
          return await this.executeSubProcessNode(executionContext);
        case 'parallel':
          return await this.executeParallelNode(
            executionContext.nodeInstance,
            executionContext
          );
        default:
          return {
            success: false,
            error: `Unknown node type: ${executionContext.nodeInstance.nodeType}`
          };
      }
    } catch (error) {
      this.logger.error('Failed to execute node', {
        error,
        currentInstance: executionContext.nodeInstance
      });
      return {
        success: false,
        error: 'Failed to execute node',
        errorDetails: error
      };
    }
  }

  /**
   * æ›´æ–°èŠ‚ç‚¹çŠ¶æ€
   */
  async updateNodeStatus(
    nodeId: number,
    status: string,
    errorMessage?: string,
    errorDetails?: any
  ): Promise<ServiceResult<boolean>> {
    const result = await this.nodeInstanceRepository.updateStatus(
      nodeId,
      status as any,
      errorMessage,
      errorDetails
    );

    return {
      success: result.success,
      error: result.success
        ? undefined
        : result.error?.message || 'Failed to update node status'
    };
  }

  /**
   * è·å–èŠ‚ç‚¹å®ä¾‹
   */
  async getNodeInstance(
    workflowInstanceId: number,
    nodeId: string
  ): Promise<ServiceResult<NodeInstance>> {
    const result = await this.nodeInstanceRepository.findByWorkflowAndNodeId(
      workflowInstanceId,
      nodeId
    );
    if (!result.success) {
      return {
        success: false,
        error: result.error?.message || 'Failed to get node instance'
      };
    }

    // æ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦å­˜åœ¨
    if (!result.data) {
      return {
        success: false,
        error: `Node instance not found: ${nodeId} in workflow ${workflowInstanceId}`
      };
    }

    return {
      success: true,
      data: this.mapToBusinessModel(result.data)
    };
  }

  /**
   * åˆ›å»ºèŠ‚ç‚¹å®ä¾‹
   */
  async createNodeInstance(
    nodeInstance: Partial<NodeInstance>
  ): Promise<ServiceResult<NodeInstance>> {
    const newNodeInstance = {
      workflow_instance_id: nodeInstance.workflowInstanceId!,
      node_id: nodeInstance.nodeId!,
      node_name: nodeInstance.nodeName!,
      node_description: null,
      node_type: nodeInstance.nodeType!,
      executor: nodeInstance.executor || null,
      status: 'pending' as const,
      input_data: nodeInstance.inputData || null,
      output_data: null,
      timeout_seconds: null,
      retry_delay_seconds: null,
      execution_condition: null,
      error_message: null,
      error_details: null,
      started_at: null,
      completed_at: null,
      duration_ms: null,
      retry_count: 0,
      max_retries: nodeInstance.maxRetries || 3,
      parent_node_id: nodeInstance.parentNodeId || null,
      child_index: nodeInstance.childIndex || null,
      loop_progress: null,
      loop_total_count: null,
      loop_completed_count: 0,
      parallel_group_id: nodeInstance.parallelGroupId || null,
      parallel_index: nodeInstance.parallelIndex || null
    };

    const result = await this.nodeInstanceRepository.create(newNodeInstance);
    if (!result.success) {
      return {
        success: false,
        error: result.error?.message || 'Failed to create node instance'
      };
    }
    return {
      success: true,
      data: this.mapToBusinessModel(result.data!)
    };
  }

  /**
   * è§£ææ¨¡æ¿å˜é‡ï¼ˆæ ¹æ®èŠ‚ç‚¹ç±»å‹æ™ºèƒ½é€‰æ‹©ç›®æ ‡å­—æ®µï¼‰
   */
  public async resolveTemplateVariables(
    executionContext: ExecutionContext,
    variables: Record<string, any> = {},
    inputData?: Record<string, any>
  ): Promise<any> {
    const { workflowInstance } = executionContext;
    try {
      this.logger.debug('Resolving template variables', {
        workflowInstanceId: workflowInstance.id
      });

      // 1. åŸºç¡€å˜é‡ï¼ˆæ‰å¹³åŒ–ï¼‰
      const flatVariables: Record<string, any> = {};

      // å·¥ä½œæµè¾“å…¥æ•°æ®ï¼ˆä¼˜å…ˆçº§1ï¼‰
      if (workflowInstance.inputData) {
        Object.assign(flatVariables, workflowInstance.inputData);
      }

      // å·¥ä½œæµä¸Šä¸‹æ–‡æ•°æ®ï¼ˆä¼˜å…ˆçº§2ï¼‰
      if (workflowInstance.contextData) {
        Object.assign(flatVariables, workflowInstance.contextData);
      }

      // å‰ç½®èŠ‚ç‚¹è¾“å‡ºæ•°æ®ï¼ˆä¼˜å…ˆçº§4ï¼Œæœ€é«˜ï¼‰
      if (
        executionContext.previousNodeOutput &&
        executionContext.previousNodeOutput.data
      ) {
        Object.assign(flatVariables, executionContext.previousNodeOutput.data);
      }

      // å·¥ä½œæµä¸Šä¸‹æ–‡æ•°æ®ï¼ˆä¼˜å…ˆçº§2ï¼‰
      if (variables) {
        Object.assign(flatVariables, variables);
      }

      this.logger.debug('Template variables built for node', {
        flatVariableCount: Object.keys(flatVariables).length
      });

      // 2. æ ¹æ®èŠ‚ç‚¹ç±»å‹ç¡®å®šéœ€è¦è§£æçš„ç›®æ ‡å­—æ®µ
      const resolvedConfig = await this.resolveNodeTypeSpecificFields(
        flatVariables,
        inputData
      );

      this.logger.debug('Template variables resolved successfully', {
        resolvedFields: Object.keys(resolvedConfig)
      });

      return resolvedConfig;
    } catch (error) {
      this.logger.warn('Failed to resolve template variables', {
        error,
        workflowInstanceId: workflowInstance.id
      });

      // å‡ºé”™æ—¶è¿”å›ç©ºé…ç½®ï¼Œç¡®ä¿å·¥ä½œæµèƒ½ç»§ç»­æ‰§è¡Œ
      return {};
    }
  }

  /**
   * æ ¹æ®èŠ‚ç‚¹ç±»å‹è§£æç‰¹å®šå­—æ®µ
   */
  private async resolveNodeTypeSpecificFields(
    templateVariables: Record<string, any>,
    inputData?: Record<string, any>
  ): Promise<any> {
    try {
      // ç»Ÿä¸€è§£æinput_dataï¼Œä¸å†åŒºåˆ†èŠ‚ç‚¹ç±»å‹çš„é…ç½®å¤„ç†
      let resolvedConfig = {};
      if (inputData) {
        resolvedConfig = this.templateService.resolveConfigVariables(
          inputData,
          templateVariables,
          { strict: false, defaultValue: undefined }
        );
      }
      return resolvedConfig;
    } catch (error) {
      this.logger.error('Failed to resolve node type specific fields', {
        error
      });
      return {};
    }
  }

  // è¾…åŠ©æ–¹æ³•
  private mapToBusinessModel(dbModel: any): NodeInstance {
    return {
      id: dbModel.id,
      workflowInstanceId: dbModel.workflow_instance_id,
      nodeId: dbModel.node_id,
      nodeName: dbModel.node_name,
      nodeType: dbModel.node_type,
      executor: dbModel.executor,
      executorConfig: dbModel.executor_config,
      status: dbModel.status,
      inputData: dbModel.input_data,
      outputData: dbModel.output_data,
      errorMessage: dbModel.error_message,
      errorDetails: dbModel.error_details,
      startedAt: dbModel.started_at,
      completedAt: dbModel.completed_at,
      durationMs: dbModel.duration_ms,
      retryCount: dbModel.retry_count,
      maxRetries: dbModel.max_retries,
      parentNodeId: dbModel.parent_node_id,
      childIndex: dbModel.child_index,
      loopProgress: dbModel.loop_progress,
      loopTotalCount: dbModel.loop_total_count,
      loopCompletedCount: dbModel.loop_completed_count,
      parallelGroupId: dbModel.parallel_group_id,
      parallelIndex: dbModel.parallel_index,
      createdAt: dbModel.created_at,
      updatedAt: dbModel.updated_at
    };
  }

  /**
   * ç®€åŒ–ç‰ˆæœ¬ï¼šå¤„ç†å­æµç¨‹è¾“å…¥æ˜ å°„
   */
  private mapSubprocessInputSimple(
    subprocessDef: SubprocessNodeDefinition,
    executionContext: ExecutionContext
  ): Record<string, any> {
    try {
      const { workflowInstance } = executionContext;

      // æ„å»ºåŸºç¡€å˜é‡ä¸Šä¸‹æ–‡
      const baseVariables: Record<string, any> = {
        // å·¥ä½œæµè¾“å…¥æ•°æ®
        ...workflowInstance.inputData,
        // å·¥ä½œæµä¸Šä¸‹æ–‡æ•°æ®
        ...workflowInstance.contextData,
        // å‰ç½®èŠ‚ç‚¹è¾“å‡ºæ•°æ®
        ...executionContext.previousNodeOutput?.data
      };

      // å¦‚æœæ²¡æœ‰è¾“å…¥æ˜ å°„é…ç½®ï¼Œè¿”å›åŸºç¡€å˜é‡
      if (!subprocessDef.outputData) {
        this.logger.debug('No input mapping defined, using base variables');
        return baseVariables;
      }

      // åº”ç”¨è¾“å…¥æ˜ å°„
      const mappedInput: Record<string, any> = {};
      for (const [targetKey, sourceExpression] of Object.entries(
        subprocessDef.outputData
      )) {
        const resolveResult = this.templateService.evaluateExpression(
          sourceExpression,
          baseVariables
        );
        mappedInput[targetKey] = resolveResult.value;
      }

      this.logger.debug('Input mapping applied', {
        mappingCount: Object.keys(subprocessDef.outputData).length,
        mappedKeys: Object.keys(mappedInput)
      });

      return mappedInput;
    } catch (error) {
      this.logger.error('Error mapping subprocess input', {
        error,
        subprocessDef
      });
      return {};
    }
  }

  /**
   * ç®€åŒ–ç‰ˆæœ¬ï¼šå¤„ç†å­æµç¨‹è¾“å‡ºæ˜ å°„
   */
  private mapSubprocessOutputSimple(
    subprocessDef: SubprocessNodeDefinition,
    subWorkflowResult: any
  ): Record<string, any> {
    try {
      // å¦‚æœæ²¡æœ‰è¾“å‡ºæ˜ å°„é…ç½®ï¼Œè¿”å›åŸå§‹ç»“æœ
      if (!subprocessDef.outputData) {
        this.logger.debug('No output mapping defined, using raw result');
        return subWorkflowResult?.outputData || subWorkflowResult || {};
      }

      // æ„å»ºæºæ•°æ®ä¸Šä¸‹æ–‡
      const sourceData = {
        // å­å·¥ä½œæµçš„è¾“å‡ºæ•°æ®
        ...subWorkflowResult?.outputData,
        // å­å·¥ä½œæµçš„å®Œæ•´ç»“æœ
        subWorkflowResult,
        // ä¸€äº›å…ƒæ•°æ®
        executionTime: subWorkflowResult?.executionTime,
        status: subWorkflowResult?.status || 'completed'
      };

      // åº”ç”¨è¾“å‡ºæ˜ å°„
      const mappedOutput: Record<string, any> = {};
      for (const [targetKey, sourceExpression] of Object.entries(
        subprocessDef.outputData
      )) {
        const resolveResult = this.templateService.evaluateExpression(
          sourceExpression,
          sourceData
        );
        mappedOutput[targetKey] = resolveResult.value;
      }

      this.logger.debug('Output mapping applied', {
        mappingCount: Object.keys(subprocessDef.outputData).length,
        mappedKeys: Object.keys(mappedOutput)
      });

      return mappedOutput;
    } catch (error) {
      this.logger.error('Error mapping subprocess output', {
        error,
        subprocessDef
      });
      return subWorkflowResult?.outputData || {};
    }
  }
}
